---
title: "Domesticated by Technology"
date: 2025-10-31
draft: false
summary: "Efficiency gains don't create leisure because technology is selecting what kind of humans survive"
categories: ["Mindsets", "AI"]
slug: "domesticated-by-technology"
---

After every major technological breakthrough, people expect working hours to shrink. When washing machines were invented, household labor should have decreased. When the internet arrived, information access should have become more efficient. When AI emerged, repetitive work should have disappeared. But the reality is, **we're busier than ever**.

This isn't an anomaly. It's a pattern.

Most people blame capitalist greed or personal inadequacy. Both explanations are too shallow. The real issue is this: **we think we're choosing technology, but technology is choosing us**.

### Jevons Paradox: Efficiency Gains and Demand Explosion

In the 19th century, economist William Stanley Jevons observed something counterintuitive: when steam engines became more efficient and coal usage costs dropped, coal consumption increased rather than decreased. The reason was simple—**lower costs made previously unworthy tasks suddenly worthwhile**.

This is the famous Jevons Paradox: efficiency gains don't reduce resource consumption; they expand use cases, ultimately increasing total consumption.

Did washing machines make laundry easier? Yes. But simultaneously, **society's standards for "clean" rose**. What used to be acceptable cleanliness became inadequate, and more frequent washing became the new normal. The time saved was consumed by higher cleanliness standards.

Did the internet make information retrieval faster? Yes. But simultaneously, **the volume of information requiring processing grew exponentially**. A report that once needed three books now requires browsing fifty webpages, reading ten papers, and comparing three data sources. The time saved was consumed by higher information standards.

Does AI make content generation faster? Yes. But simultaneously, **output standards and competitive thresholds rose in lockstep**. What used to be just a blog post now requires images, videos, SEO, A/B tested headlines, and conversion tracking. The time saved was consumed by higher content standards.

Jevons Paradox explains why efficiency gains get absorbed, but not **why standards keep rising**. Understanding this requires looking at deeper mechanisms.

### Three Feedback Loops: Why We Can't Stop

Efficiency gains getting absorbed isn't accidental—it's the result of three reinforcing feedback loops working in concert.

**The First Loop: Cost**. Technology lowers marginal costs, making previously uneconomical activities economical. Washing machines made "daily laundry" possible, the internet made "real-time fact-checking every citation" possible, AI made "generating personalized content for each user" possible. **Falling costs expand the task surface**, and saved time immediately gets filled with new tasks.

**The Second Loop: Competition**. When everyone has washing machines, "clean" is no longer an advantage—it's baseline. When everyone has search engines, "more information" is no longer an advantage—it's baseline. When everyone has AI, "faster output" is no longer an advantage—it's baseline. **Technology converts advantages into table stakes, forcing everyone to keep raising the ante**. This is an arms race with no finish line.

**The Third Loop: Uncertainty**. The more advanced the technology, the more complex the system, the more severe the consequences of errors, and the higher the costs of audit, compliance, explanation, and accountability. AI generates content quickly, but you spend time reviewing for hallucinations, brand alignment, and potential controversies. The more automation, **the more human roles shift from "executor" to "last line of defense"**—heavier responsibility, greater pressure.

These three loops interweave into an iron cage: technology makes individual tasks easier, but simultaneously expands the task surface, raises standards, and increases audit costs. **You run faster, but the track lengthens and the finish line recedes**.

### Capitalism's Amplifiers

If it were just Jevons Paradox and three feedback loops, the problem wouldn't be this severe. What makes the "busyness paradox" irreversible are capitalism's three transmission shafts.

**First Shaft: Reinvestment Discipline**. Capitalism's core logic is profit reinvestment. Efficiency gains don't automatically convert to rest time—they get invested in the next growth round.

Look at Amazon. When AI optimized warehouse and logistics efficiency, the saved costs didn't reduce employee workload—they funded **faster delivery promises**. Two-day shipping became next-day, then same-day, then two-hour delivery. Each efficiency gain became a new service standard.

Look at SaaS companies. When platforms like Salesforce use AI to boost sales efficiency (automated emails, call summaries, predictive insights), **the logic follows that each rep can now manage more accounts and cover more territories**. Efficiency gains don't convert to shorter hours—they convert to higher expectations: "since you're more efficient now, you should close more deals."

Look at content platforms. When Netflix used recommendation algorithms to improve retention, the saved acquisition costs didn't become profits or rest time—they funded **more original content production and expansion into more countries**. Efficiency gains immediately became growth fuel.

**The default destination for gains is always "more," never "less work"**.

**Second Shaft: Superstar Effects**. After technology lowers marginal costs, scale effects and network effects intensify winner-take-all dynamics.

On YouTube and Instagram, individual creators using AI tools (auto-editing, AI voiceovers, subtitle generation, multi-language translation) can **single-handedly achieve output volumes that previously required small teams**. One person can simultaneously operate English, Spanish, and Japanese channels, publishing multiple videos daily. Yet even then, mid-tier creators barely survive because **algorithmic recommendation follows power law distribution**—creators with resources for high-production content capture 80% of traffic, leaving scraps for the rest. Technology lowered the barrier, but made competition more brutal.

In the programmer market, a 10x engineer with Cursor and Copilot can do what used to require a small team. This doesn't mean other programmers can rest—it means **hiring demand drops while expectations for those who remain skyrocket**. You must not only code but master prompt engineering, audit AI output, and rapidly iterate across ten directions. Higher bar, faster pace, more anxiety.

In consulting and design, independent advisors using AI can juggle more projects simultaneously, squeezing out **mid-sized agencies' survival space**. You're either a top expert amplifying capacity 10x with AI, or cheap labor being replaced by AI. The middle is vanishing.

Technology widens both wealth and anxiety gaps. Not because you don't work hard enough, but because **AI reinforces winner-take-all rules**.

**Third Shaft: Total Quantification**. Technology makes everything measurable, and blank time loses legitimacy.

Look at call centers. They used to track resolution rates and average response times. Now AI analyzes **conversation sentiment, word choice, pause duration, and empathy expression**. Even "compassion" gets quantified. Agents must not only solve problems but demonstrate algorithmically detectable "warmth" in every sentence.

Look at programmer work. GitHub Copilot acceptance rate, code review pass rate, PR response time, deployment frequency—all visible. You used to say "I'm thinking about architecture"; now you must prove **your thinking time generated quantifiable value**. Thinking becomes suspicious blank space that must be defended with output.

Look at content creation. It's not just about views anymore—it's dwell time, scroll depth, share rate, conversion rate. **Every second of attention gets audited**. Every paragraph, headline, image you create has data showing "readers dropped 30% here." Optimization never ends because data always reveals room for improvement.

Quantification turns leisure into laziness, "good enough" into "not enough yet."

These three shafts convert efficiency gains into work intensity. Not because capitalists are greedy (though they are), but because **the system's default settings work this way**. As long as gain distribution power stays with capital, as long as competition is relative ranking rather than absolute thresholds, as long as quantification is the foundation of management, efficiency improvements will convert to increased workload.

### AI's Special Nature: Cognitive Marginal Cost Approaches Zero

Every technological revolution triggers the "busyness paradox," but this AI wave has unique characteristics.

Past technologies primarily lowered the costs of physical labor and information processing. Washing machines replaced handwashing, search engines replaced libraries, but **the marginal cost of cognitive production remained high**. Writing an article, creating a design, coding—all still required substantial human time.

AI changes this. **For the first time, the marginal cost of cognitive production approaches zero**.

What does this mean? It means all the long-tail tasks previously abandoned as "not worth doing" are now worth doing. You used to write personalized emails only for VIP clients; now you can write them for every user. You used to create only English content; now you can do twenty languages. You used to optimize only main flows; now you can optimize every edge case.

**The task surface doesn't grow linearly—it explodes exponentially**.

Simultaneously, human roles transform. You used to be "executor"; now you're "orchestrator—auditor—accountable party." You no longer write code yourself, but you must review AI-generated code for bugs, architectural fit, and technical debt. You no longer write copy yourself, but you must judge whether AI output is accurate, creative, and brand-safe.

The more automation, **the heavier the responsibility at the last gate**. This is a cruel paradox: AI does 95% of the work, but the remaining 5% requires you to bear 100% of the responsibility.

Worse still, AI compresses rhythm. Information transmission used to have delays; waiting was legitimate. Now AI can respond 24/7, so organizations tighten SLAs and accelerate release cadence. **Wait times are deleted, buffer space vanishes, humans get locked into a perpetual feedback loop**.

### Five Gears Framework: Predicting "Busier" or "More Leisure"

Not all technology makes people busier. Some technologies genuinely created leisure (like refrigerators reducing daily shopping trips). The question is, **how do you judge whether a technology will convert gains into work or rest**?

Use five gears for quick assessment:

1. **Price Gear**: The more technology reduces costs at core bottlenecks (cognition, communication, distribution), the more it triggers task surface explosion.
2. **Scope Gear**: The more new tasks become "wasn't worth doing before, worth doing now," the busier.
3. **Competition Gear**: If evaluation criteria are relative ranking rather than absolute thresholds, technology only raises the bar without reducing pressure.
4. **Distribution Gear**: If the default destination for gains is reinvestment in growth rather than buying time, busier.
5. **Rhythm Gear**: The more technology compresses feedback cycles, the busier.

**When all five gears engage simultaneously, increased busyness is nearly inevitable**.

AI hits all five.

### Technology Domesticates Humans

Now we can return to the fundamental question: why do efficiency gains always convert to work intensity?

The standard answer: capitalist exploitation, competitive pressure, social comparison. All true, but not deep enough.

**The deeper answer: technology selects what kind of humans survive**.

We think we're choosing technology—choosing washing machines over handwashing, search engines over libraries, AI over doing it ourselves. But actually, **technology is choosing us**.

People who adopted washing machines could maintain higher cleanliness standards, gaining competitive advantage in social and professional settings, gradually outcompeting those who didn't. People who adopted search engines could acquire information faster and make better decisions, gradually outcompeting those who didn't. People who adopted AI can cover more product lines and serve more customers, gradually outcompeting those who don't.

**Technology changes "the conditions for being selected"**. When new technology appears, early adopters gain temporary advantage. But quickly, that advantage becomes table stakes, non-adopters get eliminated, and standards reset. The system doesn't care whether you want to rest; it only cares whether you meet the new standard.

This is domestication.

When we domesticated wheat, we thought we were mastering nature. But Yuval Noah Harari points out in *Sapiens* that **wheat domesticated humans**. Cultivating wheat made humans settle down, increase labor hours, and endure greater stress, but it provided higher population carrying capacity. The result: wheat-growing groups won the competition, non-wheat groups disappeared. Humans became busier, more tired, more anxious, but had no choice—**because the conditions for being selected changed**.

Technology works the same way. We think we're mastering technology; actually, **technology is redefining what kind of humans can survive**.

People who use AI can output faster, cover more scenarios, and handle more tasks. People who don't gradually lose competitiveness. The system rewards "faster, more, more intense" people and eliminates "wants to rest" people. Individual preferences are irrelevant; **collective evolutionary direction is determined by selection pressure set by technology**.

This isn't fatalism. History does have cases of converting efficiency gains into leisure—labor movements, eight-hour workdays, paid vacation. But all required **collective coordination and institutional commitment**. Without such commitment, the default outcome is technology domesticating humans, not humans mastering technology.

### Technology Amplifies Commitments, But Won't Make Them For You

Why does technological progress make people busier? Because **technology amplifies existing commitments but won't remake commitments for you**.

If your commitment is "growth first, competition supreme, prove value through output," technology will amplify that commitment, making you faster, more productive, more intense.

If your commitment is "leisure first, stability supreme, prove value through time," technology will also amplify that commitment, giving you more space to rest, think, and create.

But reality is, **most people never actively made this commitment**. Commitments are default, implicit, system-set. And the system's default settings are: reinvest gains in growth, competition determines value, quantify and manage everything.

Technology merely amplifies this default setting.

Will AI make you busier or more leisurely? The answer isn't in AI itself, but in what you **pre-commit your new productivity to**—more features, more markets, more output, or more blank time, more thinking, more leisure.

Technology won't make this choice for you. **It will just amplify your choice a hundredfold, then ask: is this really what you want?**
