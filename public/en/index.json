[{"content":"After every major technological breakthrough, people expect working hours to shrink. When washing machines were invented, household labor should have decreased. When the internet arrived, information access should have become more efficient. When AI emerged, repetitive work should have disappeared. But the reality is, we\u0026rsquo;re busier than ever.\nThis isn\u0026rsquo;t an anomaly. It\u0026rsquo;s a pattern.\nMost people blame capitalist greed or personal inadequacy. Both explanations are too shallow. The real issue is this: we think we\u0026rsquo;re choosing technology, but technology is choosing us.\nJevons Paradox: Efficiency Gains and Demand Explosion In the 19th century, economist William Stanley Jevons observed something counterintuitive: when steam engines became more efficient and coal usage costs dropped, coal consumption increased rather than decreased. The reason was simple—lower costs made previously unworthy tasks suddenly worthwhile.\nThis is the famous Jevons Paradox: efficiency gains don\u0026rsquo;t reduce resource consumption; they expand use cases, ultimately increasing total consumption.\nDid washing machines make laundry easier? Yes. But simultaneously, society\u0026rsquo;s standards for \u0026ldquo;clean\u0026rdquo; rose. What used to be acceptable cleanliness became inadequate, and more frequent washing became the new normal. The time saved was consumed by higher cleanliness standards.\nDid the internet make information retrieval faster? Yes. But simultaneously, the volume of information requiring processing grew exponentially. A report that once needed three books now requires browsing fifty webpages, reading ten papers, and comparing three data sources. The time saved was consumed by higher information standards.\nDoes AI make content generation faster? Yes. But simultaneously, output standards and competitive thresholds rose in lockstep. What used to be just a blog post now requires images, videos, SEO, A/B tested headlines, and conversion tracking. The time saved was consumed by higher content standards.\nJevons Paradox explains why efficiency gains get absorbed, but not why standards keep rising. Understanding this requires looking at deeper mechanisms.\nThree Feedback Loops: Why We Can\u0026rsquo;t Stop Efficiency gains getting absorbed isn\u0026rsquo;t accidental—it\u0026rsquo;s the result of three reinforcing feedback loops working in concert.\nThe First Loop: Cost. Technology lowers marginal costs, making previously uneconomical activities economical. Washing machines made \u0026ldquo;daily laundry\u0026rdquo; possible, the internet made \u0026ldquo;real-time fact-checking every citation\u0026rdquo; possible, AI made \u0026ldquo;generating personalized content for each user\u0026rdquo; possible. Falling costs expand the task surface, and saved time immediately gets filled with new tasks.\nThe Second Loop: Competition. When everyone has washing machines, \u0026ldquo;clean\u0026rdquo; is no longer an advantage—it\u0026rsquo;s baseline. When everyone has search engines, \u0026ldquo;more information\u0026rdquo; is no longer an advantage—it\u0026rsquo;s baseline. When everyone has AI, \u0026ldquo;faster output\u0026rdquo; is no longer an advantage—it\u0026rsquo;s baseline. Technology converts advantages into table stakes, forcing everyone to keep raising the ante. This is an arms race with no finish line.\nThe Third Loop: Uncertainty. The more advanced the technology, the more complex the system, the more severe the consequences of errors, and the higher the costs of audit, compliance, explanation, and accountability. AI generates content quickly, but you spend time reviewing for hallucinations, brand alignment, and potential controversies. The more automation, the more human roles shift from \u0026ldquo;executor\u0026rdquo; to \u0026ldquo;last line of defense\u0026rdquo;—heavier responsibility, greater pressure.\nThese three loops interweave into an iron cage: technology makes individual tasks easier, but simultaneously expands the task surface, raises standards, and increases audit costs. You run faster, but the track lengthens and the finish line recedes.\nCapitalism\u0026rsquo;s Amplifiers If it were just Jevons Paradox and three feedback loops, the problem wouldn\u0026rsquo;t be this severe. What makes the \u0026ldquo;busyness paradox\u0026rdquo; irreversible are capitalism\u0026rsquo;s three transmission shafts.\nFirst Shaft: Reinvestment Discipline. Capitalism\u0026rsquo;s core logic is profit reinvestment. Efficiency gains don\u0026rsquo;t automatically convert to rest time—they get invested in the next growth round.\nLook at Amazon. When AI optimized warehouse and logistics efficiency, the saved costs didn\u0026rsquo;t reduce employee workload—they funded faster delivery promises. Two-day shipping became next-day, then same-day, then two-hour delivery. Each efficiency gain became a new service standard.\nLook at SaaS companies. When platforms like Salesforce use AI to boost sales efficiency (automated emails, call summaries, predictive insights), the logic follows that each rep can now manage more accounts and cover more territories. Efficiency gains don\u0026rsquo;t convert to shorter hours—they convert to higher expectations: \u0026ldquo;since you\u0026rsquo;re more efficient now, you should close more deals.\u0026rdquo;\nLook at content platforms. When Netflix used recommendation algorithms to improve retention, the saved acquisition costs didn\u0026rsquo;t become profits or rest time—they funded more original content production and expansion into more countries. Efficiency gains immediately became growth fuel.\nThe default destination for gains is always \u0026ldquo;more,\u0026rdquo; never \u0026ldquo;less work\u0026rdquo;.\nSecond Shaft: Superstar Effects. After technology lowers marginal costs, scale effects and network effects intensify winner-take-all dynamics.\nOn YouTube and Instagram, individual creators using AI tools (auto-editing, AI voiceovers, subtitle generation, multi-language translation) can single-handedly achieve output volumes that previously required small teams. One person can simultaneously operate English, Spanish, and Japanese channels, publishing multiple videos daily. Yet even then, mid-tier creators barely survive because algorithmic recommendation follows power law distribution—creators with resources for high-production content capture 80% of traffic, leaving scraps for the rest. Technology lowered the barrier, but made competition more brutal.\nIn the programmer market, a 10x engineer with Cursor and Copilot can do what used to require a small team. This doesn\u0026rsquo;t mean other programmers can rest—it means hiring demand drops while expectations for those who remain skyrocket. You must not only code but master prompt engineering, audit AI output, and rapidly iterate across ten directions. Higher bar, faster pace, more anxiety.\nIn consulting and design, independent advisors using AI can juggle more projects simultaneously, squeezing out mid-sized agencies\u0026rsquo; survival space. You\u0026rsquo;re either a top expert amplifying capacity 10x with AI, or cheap labor being replaced by AI. The middle is vanishing.\nTechnology widens both wealth and anxiety gaps. Not because you don\u0026rsquo;t work hard enough, but because AI reinforces winner-take-all rules.\nThird Shaft: Total Quantification. Technology makes everything measurable, and blank time loses legitimacy.\nLook at call centers. They used to track resolution rates and average response times. Now AI analyzes conversation sentiment, word choice, pause duration, and empathy expression. Even \u0026ldquo;compassion\u0026rdquo; gets quantified. Agents must not only solve problems but demonstrate algorithmically detectable \u0026ldquo;warmth\u0026rdquo; in every sentence.\nLook at programmer work. GitHub Copilot acceptance rate, code review pass rate, PR response time, deployment frequency—all visible. You used to say \u0026ldquo;I\u0026rsquo;m thinking about architecture\u0026rdquo;; now you must prove your thinking time generated quantifiable value. Thinking becomes suspicious blank space that must be defended with output.\nLook at content creation. It\u0026rsquo;s not just about views anymore—it\u0026rsquo;s dwell time, scroll depth, share rate, conversion rate. Every second of attention gets audited. Every paragraph, headline, image you create has data showing \u0026ldquo;readers dropped 30% here.\u0026rdquo; Optimization never ends because data always reveals room for improvement.\nQuantification turns leisure into laziness, \u0026ldquo;good enough\u0026rdquo; into \u0026ldquo;not enough yet.\u0026rdquo;\nThese three shafts convert efficiency gains into work intensity. Not because capitalists are greedy (though they are), but because the system\u0026rsquo;s default settings work this way. As long as gain distribution power stays with capital, as long as competition is relative ranking rather than absolute thresholds, as long as quantification is the foundation of management, efficiency improvements will convert to increased workload.\nAI\u0026rsquo;s Special Nature: Cognitive Marginal Cost Approaches Zero Every technological revolution triggers the \u0026ldquo;busyness paradox,\u0026rdquo; but this AI wave has unique characteristics.\nPast technologies primarily lowered the costs of physical labor and information processing. Washing machines replaced handwashing, search engines replaced libraries, but the marginal cost of cognitive production remained high. Writing an article, creating a design, coding—all still required substantial human time.\nAI changes this. For the first time, the marginal cost of cognitive production approaches zero.\nWhat does this mean? It means all the long-tail tasks previously abandoned as \u0026ldquo;not worth doing\u0026rdquo; are now worth doing. You used to write personalized emails only for VIP clients; now you can write them for every user. You used to create only English content; now you can do twenty languages. You used to optimize only main flows; now you can optimize every edge case.\nThe task surface doesn\u0026rsquo;t grow linearly—it explodes exponentially.\nSimultaneously, human roles transform. You used to be \u0026ldquo;executor\u0026rdquo;; now you\u0026rsquo;re \u0026ldquo;orchestrator—auditor—accountable party.\u0026rdquo; You no longer write code yourself, but you must review AI-generated code for bugs, architectural fit, and technical debt. You no longer write copy yourself, but you must judge whether AI output is accurate, creative, and brand-safe.\nThe more automation, the heavier the responsibility at the last gate. This is a cruel paradox: AI does 95% of the work, but the remaining 5% requires you to bear 100% of the responsibility.\nWorse still, AI compresses rhythm. Information transmission used to have delays; waiting was legitimate. Now AI can respond 24/7, so organizations tighten SLAs and accelerate release cadence. Wait times are deleted, buffer space vanishes, humans get locked into a perpetual feedback loop.\nFive Gears Framework: Predicting \u0026ldquo;Busier\u0026rdquo; or \u0026ldquo;More Leisure\u0026rdquo; Not all technology makes people busier. Some technologies genuinely created leisure (like refrigerators reducing daily shopping trips). The question is, how do you judge whether a technology will convert gains into work or rest?\nUse five gears for quick assessment:\nPrice Gear: The more technology reduces costs at core bottlenecks (cognition, communication, distribution), the more it triggers task surface explosion. Scope Gear: The more new tasks become \u0026ldquo;wasn\u0026rsquo;t worth doing before, worth doing now,\u0026rdquo; the busier. Competition Gear: If evaluation criteria are relative ranking rather than absolute thresholds, technology only raises the bar without reducing pressure. Distribution Gear: If the default destination for gains is reinvestment in growth rather than buying time, busier. Rhythm Gear: The more technology compresses feedback cycles, the busier. When all five gears engage simultaneously, increased busyness is nearly inevitable.\nAI hits all five.\nTechnology Domesticates Humans Now we can return to the fundamental question: why do efficiency gains always convert to work intensity?\nThe standard answer: capitalist exploitation, competitive pressure, social comparison. All true, but not deep enough.\nThe deeper answer: technology selects what kind of humans survive.\nWe think we\u0026rsquo;re choosing technology—choosing washing machines over handwashing, search engines over libraries, AI over doing it ourselves. But actually, technology is choosing us.\nPeople who adopted washing machines could maintain higher cleanliness standards, gaining competitive advantage in social and professional settings, gradually outcompeting those who didn\u0026rsquo;t. People who adopted search engines could acquire information faster and make better decisions, gradually outcompeting those who didn\u0026rsquo;t. People who adopted AI can cover more product lines and serve more customers, gradually outcompeting those who don\u0026rsquo;t.\nTechnology changes \u0026ldquo;the conditions for being selected\u0026rdquo;. When new technology appears, early adopters gain temporary advantage. But quickly, that advantage becomes table stakes, non-adopters get eliminated, and standards reset. The system doesn\u0026rsquo;t care whether you want to rest; it only cares whether you meet the new standard.\nThis is domestication.\nWhen we domesticated wheat, we thought we were mastering nature. But Yuval Noah Harari points out in Sapiens that wheat domesticated humans. Cultivating wheat made humans settle down, increase labor hours, and endure greater stress, but it provided higher population carrying capacity. The result: wheat-growing groups won the competition, non-wheat groups disappeared. Humans became busier, more tired, more anxious, but had no choice—because the conditions for being selected changed.\nTechnology works the same way. We think we\u0026rsquo;re mastering technology; actually, technology is redefining what kind of humans can survive.\nPeople who use AI can output faster, cover more scenarios, and handle more tasks. People who don\u0026rsquo;t gradually lose competitiveness. The system rewards \u0026ldquo;faster, more, more intense\u0026rdquo; people and eliminates \u0026ldquo;wants to rest\u0026rdquo; people. Individual preferences are irrelevant; collective evolutionary direction is determined by selection pressure set by technology.\nThis isn\u0026rsquo;t fatalism. History does have cases of converting efficiency gains into leisure—labor movements, eight-hour workdays, paid vacation. But all required collective coordination and institutional commitment. Without such commitment, the default outcome is technology domesticating humans, not humans mastering technology.\nTechnology Amplifies Commitments, But Won\u0026rsquo;t Make Them For You Why does technological progress make people busier? Because technology amplifies existing commitments but won\u0026rsquo;t remake commitments for you.\nIf your commitment is \u0026ldquo;growth first, competition supreme, prove value through output,\u0026rdquo; technology will amplify that commitment, making you faster, more productive, more intense.\nIf your commitment is \u0026ldquo;leisure first, stability supreme, prove value through time,\u0026rdquo; technology will also amplify that commitment, giving you more space to rest, think, and create.\nBut reality is, most people never actively made this commitment. Commitments are default, implicit, system-set. And the system\u0026rsquo;s default settings are: reinvest gains in growth, competition determines value, quantify and manage everything.\nTechnology merely amplifies this default setting.\nWill AI make you busier or more leisurely? The answer isn\u0026rsquo;t in AI itself, but in what you pre-commit your new productivity to—more features, more markets, more output, or more blank time, more thinking, more leisure.\nTechnology won\u0026rsquo;t make this choice for you. It will just amplify your choice a hundredfold, then ask: is this really what you want?\n","permalink":"https://www.hancezhang.blog/en/posts/domesticated-by-technology/","summary":"Efficiency gains don\u0026rsquo;t create leisure because technology is selecting what kind of humans survive","title":"Domesticated by Technology"},{"content":"Dropping out to start a company is starting to feel like a mimetic trap. It\u0026rsquo;s become the default advice in AI, and like any default, you should be suspicious of it.\nI feel the pressure myself. People are constantly telling me I should start a company. With leaders like Sam Altman saying this is the best time in history to do it, you feel almost stupid if you don\u0026rsquo;t.\nOn paper, they\u0026rsquo;re right. Technology is moving faster than ever. The market isn\u0026rsquo;t saturated. And it\u0026rsquo;s hard to argue that four years of tuition for an increasingly inefficient curriculum is a better deal than teaching yourself with the tools we have now.\nBut the question isn\u0026rsquo;t whether it\u0026rsquo;s a good time to start a company. It\u0026rsquo;s whether you actually want the lifestyle that comes with it. When you commit to a startup, you\u0026rsquo;re committing to a way of life for the next 3–5 years. In many ways, I\u0026rsquo;m already living it, and I love it. But I\u0026rsquo;m still not sure I should start a company. Why?\nBecause the idea of being \u0026ldquo;contrarian\u0026rdquo; has become its own form of consensus.\nAfter I got into startups and investing, I became addicted to the idea of being \u0026ldquo;contrarian and right.\u0026rdquo; Peter Thiel was a big influence. And once you read Thiel, you inevitably run into René Girard and mimetic theory. I started to see that in some circles, \u0026ldquo;being contrarian\u0026rdquo; and \u0026ldquo;not caring what other people think\u0026rdquo; became a new kind of political correctness. I even started calling myself a contrarian.\nBeing an independent thinker still matters. It\u0026rsquo;s the only way to do great work or build a life that\u0026rsquo;s truly your own. You have to know whether you believe something because it\u0026rsquo;s true, or because everyone around you believes it.\nBut in the current AI gold rush, the consensus is that you should be a contrarian. The most mimetic thing you can do is announce that you\u0026rsquo;re not driven by mimesis. You see it at events. People perform contrarianism. They dress and talk in deliberately eccentric ways, hoping to seem a little manic, because they think that\u0026rsquo;s the archetype VCs look for in great founders.\nWanting to be seen as a contrarian is the opposite of being one. It\u0026rsquo;s a signal that you care deeply what other people think. It\u0026rsquo;s a costume. Darkly funny, after the media decided Elon Musk was on the autism spectrum, you started to see founders performing that persona too.\nWe\u0026rsquo;re social animals. You can\u0026rsquo;t just delete the desire for recognition. It\u0026rsquo;s as fundamental as the drive for food or sex. I went through a phase of trying to prove I was a contrarian. It got me some attention, but it also pushed me into a kind of self-imposed isolation. I felt a need to disagree with people almost by default. The result wasn\u0026rsquo;t a feeling of accomplishment. It was a deep loneliness.\nWhat I learned is that desire is like any other force. You can\u0026rsquo;t suppress it with pure rationality, but you also can\u0026rsquo;t let it run your life. Both are recipes for misery. You have to learn to steer it.\nI used to think that my old life—the one that followed consensus—was simply wrong. Then I reacted against it, running to the opposite extreme. Now, after seeing the trap of performed nonconformity, I\u0026rsquo;m trying to find a balance.\nPerhaps the truly contrarian move, right now, is to ignore the pressure to drop out and build a startup. Perhaps it\u0026rsquo;s to quietly choose the life that fits you, not the costume that fits the moment.\n","permalink":"https://www.hancezhang.blog/en/posts/mimetic-desire/","summary":"In the AI gold rush, \u0026lsquo;being contrarian\u0026rsquo; has become its own consensus; the real move is choosing the life that fits you.","title":"Mimetic Desire and the Performance of Contrarianism"},{"content":"The day GPT-5 arrived, model felt a bit stronger, but it quickly became clear that simply measuring its power in a chat window was missing the forest for the trees. The race for benchmark supremacy is becoming a distraction. The truly groundbreaking applications aren\u0026rsquo;t emerging from a slightly smarter model, but from a richer environment that allows that model to act. The focus is shifting from the model itself to the system that unleashes its potential.\nSo, when I look at a new model release now, I find myself skipping the benchmarks and heading straight for the developer documentation. The most telling signals aren\u0026rsquo;t in the leaderboards, but in the API design, the cost curves, the context management, and the in-context capabilities. These are the signals that show us where the real work—and the real value—is. GPT-5 is a watershed moment not because it\u0026rsquo;s the new king of the hill, but because it’s the clearest signal yet that the king-maker is the environment.\nWhat Is an \u0026ldquo;Environment\u0026rdquo;? When I say \u0026ldquo;environment,\u0026rdquo; I don\u0026rsquo;t just mean the dependencies. I mean the entire set of external conditions and mechanisms that allow a model to perform real-world tasks effectively. It\u0026rsquo;s the scaffold that turns a powerful but inert model into a useful, reliable agent.\nThis scaffold is made of several distinct components:\nData: First-party user data, domain knowledge, and a closed feedback loop. This provides the specific, proprietary context that makes a generic model feel like your model. Context and Memory: Sophisticated retrieval, session memory, and persistent user profiles. It’s about remembering what matters, not just having a long context window. Execution and Orchestration: The runtime that connects the model to the real world via tools and APIs. It handles task decomposition, failure recovery, and reliable execution. Interaction and Workflow: The user-facing layer that shapes the model\u0026rsquo;s power into a useful workflow, giving users clarity, control, and the ability to guide and correct the agent. Runtime and Cost: The practical mechanics of performance and economics. An environment must be efficient in terms of speed, concurrency, and token usage to be viable. The key insight is that the same model, when supported by different environments, can exhibit performance differences of an order of magnitude. A model is a powerful engine, but the environment is the vehicle—the transmission, the wheels, the steering—that determines where it can go and how fast.\nThe \u0026ldquo;Environment-Friendly\u0026rdquo; Signals from GPT-5 What I found most exciting about the GPT-5 release wasn\u0026rsquo;t the headline capabilities, but the subtle, \u0026ldquo;environment-friendly\u0026rdquo; shifts in the platform itself.\nFirst, the API is significantly more robust. The documentation is clearer, the parameters are more semantically meaningful. This is a clear nod to developers who are building complex orchestration layers on top.\nSecond, the unit cost of intelligence continues to fall. With more granular pricing tiers and inference options, it becomes economically feasible to build \u0026ldquo;thicker\u0026rdquo; environments. You can afford to make more speculative calls, build more sophisticated caching strategies, and run more complex agentic loops without breaking the bank.\nFinally, the product is full of developer-centric details. This isn\u0026rsquo;t just polish; it\u0026rsquo;s a significant engineering and strategic shift. For a long time, the conventional wisdom was that the market was neatly divided: Anthropic was the developer-centric company focused on robust APIs, while OpenAI\u0026rsquo;s strength was its massive consumer-facing product. This latest release blurs that line completely. By investing so heavily in the developer experience, OpenAI is implicitly acknowledging a crucial insight: while their consumer business is enormous, the path to truly massive scale runs through the API. It\u0026rsquo;s a partial admission that consumer-led growth has its limits, and that the future depends on empowering an entire ecosystem of developers to build on their platform. They are admitting, through their actions, that the future is environment-first.\nCase Study 1: Coding—Where Small Teams Won by Building Thicker Environments The coding assistant space is the clearest proof of the environment thesis. Early assistants were just clunky chat interfaces. You\u0026rsquo;d paste code and ask for changes.\nThen, smaller teams like Cursor changed the game. They didn\u0026rsquo;t build a better model; they built a better environment inside the IDE. By integrating the model with the entire project context, dependency graph, and a tight execution loop (suggest -\u0026gt; run -\u0026gt; test -\u0026gt; feedback), they turned a simple chat into a true collaboration. The experience became a granular partnership on code, not just a conversation about it.\nThe big players like Claude Code are now racing to replicate this deep integration, but they\u0026rsquo;re following a path blazed by others. It proves the core lesson: when everyone has the same powerful engine (the LLM), the winner is the one who builds the best car around it.\nCase Study 2: Education—The Complementarity of Duolingo and ChatGPT Consider Duolingo. Its strength isn\u0026rsquo;t its AI, but its meticulously crafted learning environment. It has a structured curriculum that guides you from one concept to the next, a powerful gamification and retention engine that keeps you coming back, and a tight feedback loop of quizzes and corrections.\nWhen I use ChatGPT for language practice, the experience is completely different. It\u0026rsquo;s an incredibly powerful and flexible conversation partner. I can explore any topic, ask for nuanced explanations, and get personalized practice. But it has no curriculum, no memory of what I\u0026rsquo;ve learned, and no long-term plan for my progress.\nThis highlights the power of a vertical-specific environment. In a future where Duolingo can plug in a model as powerful as GPT-5 via an API, its existing environment becomes a massive amplifier. It can combine its structured, motivating framework with the fluid, conversational power of a top-tier model. The model becomes a component, a super-powered processor inside a machine that is already expert at teaching.\nThis is the pattern we\u0026rsquo;ll see in many verticals. The best educational tool won\u0026rsquo;t be a generic chatbot; it will be a purpose-built \u0026ldquo;teaching machine\u0026rdquo; that embeds a powerful generic model within its specialized environment.\nRedrawing the Lines: The Model Layer vs. the Environment Layer This leads to a natural division of labor in the industry.\nThe model layer is commoditizing. We have several major players (OpenAI, Anthropic, Google, Mistral) and a vibrant open-source ecosystem, all pushing in the same direction. The quality gap is narrowing, and competition is increasingly shifting to price, speed, and modality options (e.g., longer context, finer-grained tool use).\nIt\u0026rsquo;s highly unlikely that these model providers will successfully capture all the valuable vertical environments. The reasons are simple:\nOrganizational Focus: The number of valuable, specific verticals is immense. A single company cannot focus on building deep, best-in-class solutions for coding, education, healthcare, law, and finance simultaneously. Engineering and Compliance Overhead: The details matter. The engineering challenges and compliance requirements for a medical AI are vastly different from those for a legal AI. These are deep moats that require specialized expertise. The Economics of APIs: The API business is incredibly attractive. By providing the \u0026ldquo;picks and shovels,\u0026rdquo; model providers benefit from the entire ecosystem\u0026rsquo;s innovation. Shutting down APIs to compete in a few verticals would mean sacrificing the immense marginal revenue and ecosystem energy from all the others. The logical conclusion is a stable, two-layer system: the model as infrastructure, and the environment as the product.\nCounterarguments and Rebuttals There are a few common objections to this view.\nCounterargument A: A major provider will close its API and vertically integrate to capture all the value in vertical environment. Rebuttal: This is unlikely to succeed. The competitive landscape guarantees that APIs are a permanent feature of the market. If one major provider closes its API, another will immediately step in to capture those customers. As long as high-quality APIs are available—and they will be—a model provider cannot realistically outcompete a vertical-specific company that has a superior environment built on deep experience, proprietary data, and specialized workflows. Counterargument B: A universal \u0026ldquo;Agent OS\u0026rdquo; will emerge and absorb all vertical applications. Rebuttal: A general-purpose OS will solve for breadth, but vertical applications will always win on depth, compliance, and proprietary data. You might use a general agent to book a flight, but you\u0026rsquo;ll use a specialized, trusted agent to review a legal contract or diagnose a medical issue. The two will coexist. ","permalink":"https://www.hancezhang.blog/en/posts/gpt5/","summary":"The model and product layers in the AI industry are more clearly separated than ever.","title":"GPT-5 Is the Watershed: From 'Model Will Absorb Everything' to 'Environment Is What Matters'"},{"content":"Naval Ravikant famously outlined a hierarchy of leverage. The oldest is labor, or the people who work for you. It’s powerful but messy. Managing people is hard because aligning them is hard, and the communication overhead grows faster than the team size. These systems, built to optimize for stability and consensus, are necessary for managing labor. In most parts of society—governments, large corporations, even social circles—being contrarian and right doesn’t reward you. It often gets you into trouble.\nBut the worlds of startups and investing are different. They are two of the few places where being contrarian and right is not just tolerated, but is the very source of outsized returns. You don\u0026rsquo;t need rich consensus to buy a stock or start a company. In fact, consensus is often a sign that the opportunity is gone. This works because these fields have started to move beyond labor as their primary lever, relying instead on capital and code. Code is a fantastic form of leverage: write it once, and it can be run a million times for nearly zero marginal cost. It’s permissionless and scalable.\nThis fundamental insight explains why I’ve always done my best work either alone or in very small teams. The need for rich consensus—that fragile, expensive state of agreement among many people—is a tax on every new idea. For years, I thought this was just a personal quirk, but I’ve come to realize it’s a core principle of how value is created.\nAnd as technology shifts the dominant form of leverage again, the importance of that consensus is starting to fade. I believe we are now in the early days of a new, even more powerful form of leverage: compute.\nIn fields dense with information that can be automated, compute is becoming a more efficient and scalable lever than labor, code, or capital. AI is the key that has unlocked this. It has lowered the barrier to orchestrating vast amounts of computational power from an expert-level engineering task to something a single creator can do. This shift is poised to fundamentally change how we build teams, design organizations, and distribute rewards.\nFrom Coordinating People to Orchestrating Compute The core task of building something is changing. It used to be about finding the right people and coordinating their efforts. Now, it\u0026rsquo;s increasingly about defining a problem clearly and directing computational resources to solve it. AI allows us to \u0026ldquo;outsource\u0026rdquo; tasks not to other people, but to models and agents. A single person can now translate an idea into a product, a piece of research, or a creative work with far less human coordination.\nWe can describe this with a simple model. Think of the total work required to achieve a goal as a constant. This work is a function of the number of people, the compute they can wield, and some external factors.\nA simplified equation might look like this:\nWork = N × Cᵖ × f(Data, Clarity, Distribution)\nLet’s break this down:\nN is the number of people (headcount). C is the compute per person—the amount of computational power an individual can effectively manage. p is the efficiency exponent of that compute. If p = 1, every unit of compute is perfectly productive. In reality, p \u0026lt; 1 because there are orchestration overheads. f(\u0026hellip;) is a multiplier for external constraints, like the availability of good data, the clarity of the problem, and the ability to distribute the final product. For a fixed amount of Work, if C (compute per person) goes up, and better tools make it easier to manage that compute (pushing p closer to 1), then the optimal number of people, N, must go down.\nThis isn\u0026rsquo;t a brand-new phenomenon. The rise of cloud computing and CI/CD pipelines already proved this model on a smaller scale. But AI has increased the slope of this curve by an order of magnitude.\nOf course, this model has limits. You can hit orchestration saturation, where you have more compute than one person can effectively manage, causing your efficiency (p) to drop. Or you can be bottlenecked by the external factors (f). If you don\u0026rsquo;t have good data or a clear problem, all the compute in the world will just spin its wheels. And if you can\u0026rsquo;t reach users, your brilliant, compute-generated product will go nowhere.\nLet\u0026rsquo;s make this concrete with an example.\nThe S-Curve of AI Coding Look at software development. The amount of compute available to each engineer (C) is steadily rising, thanks to AI coding assistants. As these tools get better, a small team—or even a single developer—can achieve the same output (Work) that once required a larger team. The number of people (N) required is going down.\nWe can already see the metrics changing. Imagine a team\u0026rsquo;s goal is to ship 10 new features per quarter. In the past, an eight-person team might get bogged down for days by a backlog of code reviews (PRs). Now, a four-person team, armed with a powerful AI assistant, can automatically generate boilerplate code, unit tests, and even refactoring suggestions, cutting review time down to hours. They still ship the 10 features, but with half the people and dramatically lower coordination costs.\nThe debate isn\u0026rsquo;t about whether AI improves productivity; it\u0026rsquo;s about recognizing that the shape of productivity is changing. It\u0026rsquo;s becoming less about the number of engineers and more about the thickness of the compute layer supporting each one.\nThis leads to a new kind of organization: a thin core with thick compute. The core team is small, focused on strategy and defining clear objectives. The execution is handled by a vast periphery of AI agents and automated workflows. A company like Midjourney is a perfect example. Its core team is tiny, focused on research, product vision, and model tuning. Its \u0026ldquo;workforce\u0026rdquo; is an infinitely scalable layer of compute that serves millions of users. They don\u0026rsquo;t hire hundreds of artists; they orchestrate GPUs. This is the \u0026ldquo;thin core, thick compute\u0026rdquo; model in action. In this model, the rewards for being \u0026ldquo;contrarian and right\u0026rdquo; are more direct. You don\u0026rsquo;t need to convince a committee. You just need to convince the market, and the market rewards results, not alignment.\nWill Compute Become the New Means of Production? If compute is a new factor of production, we have to ask about its distribution. Like land, compute requires capital to acquire (GPUs, cloud credits, energy). It is rivalrous and has economies of scale.\nThis leads to the \u0026ldquo;compute landlord\u0026rdquo; hypothesis. Will a few cloud providers and chip manufacturers become oligarchs, extracting rent from everyone else who becomes a \u0026ldquo;compute tenant\u0026rdquo;? It\u0026rsquo;s possible.\nBut there are powerful counter-forces. Open-source models are democratizing access. Community-driven projects are pooling GPU resources. National industrial policies are trying to prevent monopolies. And as new chips are released, older, less powerful ones will flood the market, making a certain baseline of compute accessible to almost everyone. Look at the open-source communities around models like Llama or Stable Diffusion. Many individual developers are running and fine-tuning these models on consumer-grade GPUs (like an RTX 4090). This is like digital-age subsistence farming; while it can\u0026rsquo;t compete with industrial-scale \u0026ldquo;compute landlords\u0026rdquo; like AWS or Google Cloud, it ensures the means of production are not entirely monopolized.\nThe long-term trend for compute prices is down, and access is broadening, following a version of Wright\u0026rsquo;s Law. However, the cutting edge of high-performance compute will likely remain a gated resource for some time, creating a new kind of inequality.\nWhere This Model Breaks Compute is not a silver bullet. It is the best form of leverage only under certain conditions.\nIt works best when a problem can be formally defined, when data is abundant, and when distribution is a solvable problem. If your challenge is building a brand, navigating a complex regulatory environment, or managing a physical supply chain, then other forms of leverage—like capital, media, or even old-fashioned labor—may still be superior. For example, consider building a new hospital. You can use compute to design the building and optimize patient flow (handling the \u0026ldquo;bits\u0026rdquo;). But you still need to deal with zoning laws, get permits, manage construction crews, and build trust with the local community. These are problems of the \u0026ldquo;human\u0026rdquo; world, where relationships, trust, and navigating bureaucracy—the traditional levers of labor and social capital—are far more important than raw compute.\nLarge companies won\u0026rsquo;t disappear. They can still win on their existing moats: distribution channels, proprietary data, and compliance machinery. Compute is an accelerator, not the moat itself.\nFurthermore, the price of compute isn\u0026rsquo;t guaranteed to fall smoothly. Energy costs, chip shortages, and geopolitics can all raise the price of \u0026lsquo;C\u0026rsquo;, slowing down the S-curve of adoption.\n","permalink":"https://www.hancezhang.blog/en/posts/compute-leverage/","summary":"Rich concensus is no longer necessary as compute outperforms labor as a leverage","title":"Compute Is the New Leverage (and Probably the Best One)"},{"content":"The Misreading of Bitter Lesson It’s become a kind of mantra in AI circles: “The Bitter Lesson.”\nThe idea, from researcher Rich Sutton, is that trying to bake human knowledge into models is a short-term crutch. History shows the biggest gains come from applying massive computation to general-purpose methods.\nMany industry leaders now champion this take. They suggest the purest path is to let the LLM figure things out for itself. The more your product does this, the more “agentic” it’s considered to be.\nBut my experience building products tells a different story. The Bitter Lesson is true for pure research, but building a product requires a more dialectical view.\nPrinciple: Work With the Model, Not Against It Giving an LLM too much external knowledge can be a disaster. I call the correct approach \u0026ldquo;going with the grain.\u0026rdquo;\nAn LLM has a natural inclination, like the grain in wood. It already possesses vast prior knowledge of coding patterns and architectures. If you align your requests with its existing knowledge, you maximize effectiveness and minimize hallucinations.\nAttempting to force an LLM to learn a completely foreign architecture is a recipe for failure. It not only performs poorly but also consumes the model\u0026rsquo;s finite context—its most precious resource. We should measure a model not just by its context window size, but by its \u0026ldquo;in-context capability\u0026rdquo;: the complexity of logic it can reliably execute.\nThis is where a purely dogmatic view of the Bitter Lesson falls apart. The most pragmatic and effective tools, like Base44, are fast and reliable precisely because they rely heavily on pre-built templates where the LLM’s job is simply to \u0026ldquo;fill in the blanks.\u0026rdquo; In contrast, the more dogmatic approach of relying on an LLM to generate a production-ready app from scratch usually produces terrible results, a core problem for many AI coding products today.\nBase44\u0026rsquo;s approach has trade-offs—its quality drops dramatically on requests outside its templates—but it proves a crucial point. In product development, the window of opportunity is what matters. It\u0026rsquo;s okay to build transitional products that the next model wave might render obsolete. If adding human heuristics solves a user\u0026rsquo;s problem now, it\u0026rsquo;s the right choice. Technology is a means, not an end.\nHow AI Coding is Evolving: The Four Stages The AI coding game is unfolding in four stages, with stages 2 and 3 happening concurrently.\n1. AI-Assisted Coding This is the earliest stage, represented by tab-to-complete features in early versions of tools like Cursor.\n2. AI Pair Coding This stage includes more agentic tools like Cursor Composer. The experience is like the invention of the manual transmission: powerful, but still requiring significant skill. It\u0026rsquo;s best used by experienced developers who can get a massive productivity boost, but you still need to understand the fundamentals to use it effectively.\n3. Vibe Coding 1.0 This stage, represented by products like Lovable and Bolt.new, aims to help non-developers build software. It\u0026rsquo;s like the invention of the automatic transmission, dramatically lowering the barrier to entry, even if some fine-grained control is lost. However, it still requires huge enthusiasm and patience. The interaction is often a \u0026ldquo;say one thing, do one thing\u0026rdquo; process, and its adopters are not yet the mass market, but rather AI enthusiasts and tech-savvy professionals like designers and PMs.\nMost of these tools are also \u0026ldquo;front-end only\u0026rdquo; and rely on platforms like Supabase. This means users still face a steep learning curve: they need to learn about prompting, databases, CDNs, and component variables—concepts an AI can\u0026rsquo;t easily guess for them.\nA product called Trickle AI is particularly impressive here. It uses a canvas to visualize development essentials (database, assets, version control) and has put real thought into intuitive visual edits and deployment. It’s like a top-of-the-line automatic car where the ride, comfort, and dashboard are all maxed out.\nA Personal Aside on Vibe Coding and the Future of Websites: I\u0026rsquo;m personally avoiding the frenzy to compete on front-end generation. Building a good UI is hard because visual taste is subjective, making it difficult for an AI to satisfy a human in one shot. The amount of work for a complete, visually appealing webpage is immense.\nMore importantly, I question the long-term value of webpages in an agentic future. For 20 years, websites have been key carriers of information and GUIs. But agents are now automating information retrieval and service calls. Information is being covered by products like Deep Research, and GUI operations will likely be handled by an agent\u0026rsquo;s computer-use capabilities. We already see this with ChatGPT changing how we use browsers. I worry we\u0026rsquo;re building a future with a flood of tools to create websites that only other agents will ever visit.\n4. Fully Autonomous Coding This is where I believe the future is headed, expanding the market to a much broader audience. The vision is for an AI to complete coding tasks end-to-end from a simple, high-level request, much like Deep Research does for information retrieval. The AI would infer your underlying intent and build a ready-to-use application, with subsequent edits focused on functional improvements.\nWhile this is still a future paradigm, we can achieve a constrained version of it now. The challenge with building a full web app end-to-end is immense due to the complexity of GUIs, cloud deployment, visual adjustments, and databases—not to mention token costs. But what if we betray the Bitter Lesson and use a pre-filled, template-based approach? We could constrain the UI to its simplest, most essential forms: a few buttons, using natural language to call a backend, or a simple H5 app with pre-set GUI templates. This lands squarely in the comfort zone of current AI.\nThis approach has a clear trade-off. It\u0026rsquo;s like Waymo achieving self-driving, but only in San Francisco: a powerful but geographically limited solution. Anything outside the pre-defined scope is impossible. Perhaps a \u0026ldquo;Tesla-level\u0026rdquo; product will make this obsolete in two years. But in an AI startup, you can\u0026rsquo;t wait for a lasting moat. In the face of absolute intelligence, moats are fleeting. If you can build a product that works for a year, focus on that year. Don\u0026rsquo;t make too many predictions.\nWhy Democratized Coding Won\u0026rsquo;t Kill the Market Think about the magic behind taking a photo with your phone. To a modern user, the process feels instantaneous and intuitive. But this simplicity hides immense underlying complexity, a technological marvel that evolved over decades.\nThe Hidden Complexity of a Smartphone Photo: When you press the shutter, a multi-stage process executes in milliseconds:\nLight Capture: Light passes through lenses, is focused, and hits a CMOS sensor, which converts photons into a raw digital signal. Image Processing: An Image Signal Processor (ISP) \u0026ldquo;fills in\u0026rdquo; color for each pixel, reduces noise, corrects white balance, and merges multiple exposures for HDR. Final Touches: The processor maps colors to the sRGB space, sharpens edges for clarity, and finally compresses a 12 MB data stream into a 2 MB JPEG or HEIF file. This entire pipeline is the magic that creates the \u0026ldquo;point-and-shoot\u0026rdquo; experience. I still remember when photography required a darkroom to develop film—a long, tedious, and professional process. It took years of iteration to achieve the universal access we have today, which in turn gave birth to new markets and products like Instagram.\nBut even today, the convenience of smartphone cameras hasn\u0026rsquo;t eliminated professional photographers, hobbyists, or the market for professional cameras. As the cost and complexity of a technology drop, the new market size becomes unimaginable. The smartphone expanded the photography market a hundredfold without destroying the professional niche.\nI believe the same will be true for software. AI will one day make software creation feel as simple, as instinctive, and as self-evident as taking a picture with our phones today.\nThe Future of the Creator Economy: From Ads to APIs The rise of agents leads to a deep concern for the creator economy. Many creators, like podcasters, currently survive on ad revenue. But AI is fundamentally changing consumption habits and threatening this model. Users now feed podcast audio into tools like NotebookLM to generate personalized, ad-free summaries. This behavior is becoming an expectation; you can already find comments on podcasts saying, \u0026ldquo;No AI summary? I\u0026rsquo;m not listening to this episode.\u0026rdquo;\nThis is part of a larger, inevitable shift: the entry point for information, content, and services is moving from platforms to personal agents. This will force a massive transformation in advertising, just as SEO is now adapting to AI search. The old logic of capturing user attention on a specific page is ending. In the future, user attention will be held by their personal agent.\nFor creators, the best path forward is to charge for their content, functions, or information directly. They can expose their services as an API that agents call, charging on a per-use basis. I believe this is a more rational and sustainable model than advertising. In productivity scenarios, the \u0026ldquo;browse and discover\u0026rdquo; model of app stores will be replaced by agent-led recommendations and search. Entertainment and e-commerce will be trickier, as users often enjoy the process of browsing itself.\n","permalink":"https://www.hancezhang.blog/en/posts/bitter-lesson/","summary":"The Bitter Lesson is true for research, but product development requires working with the model\u0026rsquo;s grain, not against it.","title":"Bitter Lesson, End-to-end Coding, Creator Economy"},{"content":"Startup founders love growth hacks. A/B test everything. Scale from day one. Build an MVP, get users, then tweak: feature A lifts retention X%, feature B boosts conversion Y%. It looks like methodical progress.\nBut is it? Especially before Product-Market Fit? This rush to optimize might be a dangerous distraction.\nThe truth? Growth hacks usually fail before PMF. And even after PMF, your real job is the user experience. This isn\u0026rsquo;t fluffy advice. It\u0026rsquo;s how companies like Airbnb started—by doing things that don\u0026rsquo;t scale.\nThe Illusion of Premature Optimization Before PMF, you barely know your users or their real problem. So what are you optimizing? Growth hacking then is like polishing a car with no engine. It looks busy but goes nowhere.\nThree bad assumptions lead startups astray:\nSmall, data-backed tweaks are always best. \u0026ldquo;Data-driven\u0026rdquo; automatically means scientific. Scalability is a day-one requirement. Airbnb proved these wrong. They focused on user experience, not premature optimization, and found a higher ceiling.\nDo Things That Don\u0026rsquo;t Scale Paul Graham said: \u0026ldquo;Do things that don\u0026rsquo;t scale.\u0026rdquo; Many quote it; few grasp it. Early on, unscalable work isn\u0026rsquo;t a detour; it\u0026rsquo;s the main road. Talk to users. Onboard them by hand. Be a concierge. Why?\nLearn your market: Get raw feedback. See their pain, their \u0026ldquo;aha!\u0026rdquo; moments. Dashboards don\u0026rsquo;t show this. Win a niche with service: Startups can offer an \u0026ldquo;insanely great experience\u0026rdquo; big companies can\u0026rsquo;t. Tim Cook won\u0026rsquo;t send a handwritten note; you can. This over-the-top, personal service helps you deeply understand and capture a niche. You build fierce loyalty, not just collect feedback. Create evangelists: A fantastic early experience, even for a few, makes users your sales force. This isn\u0026rsquo;t anti-data. It\u0026rsquo;s about the right kind of learning before PMF.\nAirbnb\u0026rsquo;s Masterclass: From 10-Star Dreams to Scalable Reality Airbnb didn\u0026rsquo;t A/B test button colors. They obsessed over the user\u0026rsquo;s journey. Brian Chesky pushed for a \u0026ldquo;10-star experience.\u0026rdquo;\n1. Designing \u0026ldquo;10-Star Experience\u0026rdquo;\nWhat\u0026rsquo;s a 10-star experience? Chesky made his team imagine:\n5-star: Arrive, host lets you in. As described. (Expected) 7-star: Host welcomes you. Favorite snacks in fridge, surfboard ready. (Delightful) 10-star: Beatles-style airport arrival. 5,000 fans. (Absurd, but expands thought) 11-star: Elon Musk flies you to space. (Beyond Absurd) The goal wasn\u0026rsquo;t literal 11-stars. It was to break \u0026ldquo;good enough\u0026rdquo; thinking. Find what makes users rave. Dream big, then work back to a 6, 7, or 8-star version that\u0026rsquo;s amazing and doable.\n2. \u0026ldquo;Snow White Storyboards\u0026rdquo;: Scripting the Perfect Journey\nTo make this real, Airbnb hired a Pixar animator. They storyboarded the entire journey—guest, host, employee—in 45 frames. Each showed context, emotion, motivation.\nThis \u0026ldquo;Snow White\u0026rdquo; method was powerful:\nIt made everyone see the whole experience, not just features for PMs to A/B test. It pinpointed key emotional moments: check-in, first contact, trust. This is where you forge user love. It created a shared \u0026ldquo;movie\u0026rdquo; for the whole company to align expectations. These storyboards showed where to aim for 10-star moments.\n3. From Unscalable Craft to Scalable Systems\nThis is where \u0026ldquo;doing things that don\u0026rsquo;t scale\u0026rdquo; met the 10-star dream. Airbnb manually prototyped these perfect experiences for a few users. They had to prove they were worth scaling.\nPro Photos (2009): NYC listings tanked. Bad photos? Gebbia and Chesky, armed with a rented camera, literally went door-to-door in New York, knocking on hosts\u0026rsquo; doors and offering to take better pictures of their apartments. They weren\u0026rsquo;t professional photographers, but they knew good photos mattered. Totally unscalable. Result? NYC revenue doubled in a week. Proof: pro photos convert. Then they built a scalable photo program. Living with Hosts: Founders stayed in hosts\u0026rsquo; homes. They took notes. This led to profiles and two-way reviews. No algorithm did this. Just deep, unscalable empathy. Ricardo\u0026rsquo;s Perfect Trip: The team gave one guest, Ricardo, a 10-star SF trip. Airport pickup, curated events. Ricardo cried with joy. Proof: \u0026ldquo;human connection\u0026rdquo; was huge. The scalable fix? Airbnb Experiences. The pattern:\nDefine the extreme. Storyboard it. Hand-craft it for a few users. See if it\u0026rsquo;s magic. If yes, find a way to scale the value, not the manual labor. 4. The Chesky \u0026ldquo;Critique\u0026rdquo; of A/B Testing\nChesky said, \u0026ldquo;A/B testing is moving the product decision responsibility to the user.\u0026rdquo; He wasn\u0026rsquo;t against all A/B tests. He was against misusing them for big decisions or getting stuck on tiny improvements while missing the big picture.\nIf Ford had A/B tested faster horses, he wouldn\u0026rsquo;t have invented the car.\nAirbnb\u0026rsquo;s way:\nStart with a strong hypothesis (e.g., \u0026ldquo;pro photos build trust\u0026rdquo;). Test it qualitatively, unscalably. If it works, scale it. Measure with long-term metrics (retention, referrals). Then use A/B tests to tweak the scaled version (e.g., how to offer the photo service). User Experience: The Unending Watch The lesson: obsessing over user experience isn\u0026rsquo;t just for finding PMF. It\u0026rsquo;s forever. After PMF, growth hacks on a clunky experience won\u0026rsquo;t save you. Users know a patchwork from a real journey.\nReal growth, especially early on, is often unscalable. It\u0026rsquo;s manual work, deep empathy, relentless delight. Do things that don\u0026rsquo;t scale to find what\u0026rsquo;s truly valuable. Only then do you have something worth scaling. That\u0026rsquo;s how you build more than a product. You build a phenomenon.\n","permalink":"https://www.hancezhang.blog/en/posts/user-experience/","summary":"Forget growth hacks before PMF; your first, unscalable mission is to craft a \u0026lsquo;10-star\u0026rsquo; user experience that people truly love and rave about","title":"Why Growth Hacking and A/B testing is Bullshit Before PMF"},{"content":"We\u0026rsquo;ve all been in those meetings: discussing a new idea, an innovative project, and then getting bogged down in endless debate. Everyone speaks with conviction, citing classics (or perhaps just an article they saw yesterday), but the discussion seems to go in circles, often ending inconclusively or with the decision made by the loudest voice, the highest-ranking person, or the most stubborn. Why does this happen? Especially in the realm of innovation?\nThe \u0026ldquo;Consensus Swamp\u0026rdquo; of Innovation The root of the problem is that innovation projects deal with the unknown. If you\u0026rsquo;re building a standard bridge or optimizing a mature system, experience is king. You can find people who have done similar things, and their experience constitutes reliable \u0026ldquo;facts.\u0026rdquo; Based on these facts, reaching consensus is relatively easy. But innovation is different. When you\u0026rsquo;re exploring a brand-new AI application or an unprecedented business model, there\u0026rsquo;s no existing map. Past experience might not only be useless but even detrimental. At this point, the basis for discussion is no longer reliable experience, but opinions.\n\u0026ldquo;I think users will like this feature.\u0026rdquo; \u0026ldquo;I believe this technical direction has more potential.\u0026rdquo; \u0026ldquo;I feel the market isn\u0026rsquo;t ready yet.\u0026rdquo;\nThese are all opinions, not facts. The problem with opinions is that they are extremely subjective, heavily influenced by personal background, information cocoons, and even one\u0026rsquo;s mood on a given day. Worse, opinions are difficult to falsify. You can\u0026rsquo;t logically \u0026ldquo;prove\u0026rdquo; an opinion right or wrong because it often pertains to predictions about the future and personal beliefs.\nThus, discussions based on opinions easily get stuck. Sometimes it becomes an endless debate where both sides try to persuade the other with logic, ignoring that their underlying assumptions might be fundamentally different. Sometimes, when opinions cannot be reconciled, the discussion slides into emotional confrontation, escalating into personal attacks or battles of will, which is devastating for team morale. Another common scenario is that the decision ultimately becomes a game of power or trust, where the winning idea isn\u0026rsquo;t the best one, but the opinion of the person who is more trusted or has more power.\nIn any case, the outcome is extremely inefficient and severely undermines the team\u0026rsquo;s innovative capacity and psychological safety. We waste a vast amount of precious time wallowing in the mire of \u0026ldquo;I think\u0026rdquo; instead of seeking real answers.\nAI: The Engine from \u0026ldquo;Opinion\u0026rdquo; to \u0026ldquo;Fact\u0026rdquo; Fortunately, we are in an era of explosive AI capabilities. AI, especially recent generative AI and AI-assisted development tools, gives us a powerful weapon to escape the \u0026ldquo;opinion swamp.\u0026rdquo; The key is: AI dramatically lowers the cost and barrier to \u0026ldquo;trying things out.\u0026rdquo;\nIn the past, validating an idea might have required weeks or even months of engineering effort to create a rudimentary prototype. But now, with AI Copilots, low-code platforms, and AI prototype generation tools, a product manager, a designer, or even an operations staff member can cobble together a working demo or complete a preliminary experiment in hours or days.\nFor example, want to know how a specific AI model handles a certain type of user request? Don\u0026rsquo;t guess; use an AI tool to write a simple script and run it. Want to know how users react to a new interaction method? Use AI to quickly generate an interactive prototype and test it with a few people. What these quick experiments produce are the facts we urgently need.\nHere, \u0026ldquo;fact\u0026rdquo; doesn\u0026rsquo;t mean absolute truth, but rather an observable, reproducible experimental result under specific conditions. For example: \u0026ldquo;After using model X, this specific System Prompt, and 5 rounds of interaction, the probability of it accurately understanding this complex instruction is 70%.\u0026rdquo; This is a fact. It\u0026rsquo;s objective, doesn\u0026rsquo;t involve \u0026ldquo;I think,\u0026rdquo; and provides a solid starting point for discussion.\nBuilding an Experiment-Centric Culture Leveraging this capability provided by AI, we can build a new team culture—an experiment-centric culture. The core principle of this culture is simple: encourage (or even require) the rapid transformation of ideas into low-cost, small-scale experiments, and use the facts generated by these experiments to drive discussions and decisions.\nIts operating model is roughly as follows: First, based on an understanding of the problem, clearly formulate a hypothesis. Then, design a small experiment, clearly defining what you want to verify, what prerequisites are needed (tools, data, models, etc.), and how to measure the results. The key is to keep the experiment small and fast enough. Next, use AI tools to quickly conduct the experiment, build a POC, demo, or perform simulations. Once completed, clearly record and share the facts, including the experimental process, prerequisites, and results; transparency is key. Finally, conduct discussions based on these shared facts: first find consensus (\u0026ldquo;We all saw that under condition A, the result is B\u0026rdquo;), which consolidates shared understanding; then identify disagreements and unknowns (\u0026ldquo;Why is the result different under condition C?\u0026rdquo; \u0026ldquo;This experiment didn\u0026rsquo;t cover situation D\u0026rdquo;), which naturally become directions for the next experiments. This is a continuous iterative process, gradually approaching the truth of the problem by accumulating facts.\nTo cultivate this culture, it\u0026rsquo;s necessary to encourage curiosity and initiative, embrace \u0026ldquo;failed\u0026rdquo; experiments (they also provide valuable facts, helping to eliminate wrong paths), emphasize transparent sharing, and focus discussions on the experimental process and data, rather than targeting individuals.\nSo, does this mean completely eliminating predictions about the future and \u0026ldquo;opinions\u0026rdquo;? Not at all. Innovation itself involves imagining the future. The key difference is that in an experimental culture, predictive opinions are no longer castles in the air but need to be explicitly linked to \u0026ldquo;facts\u0026rdquo; already obtained through experimentation. The discussion model becomes: \u0026ldquo;Based on the experimental results A and B that we\u0026rsquo;ve seen, I predict that if we try direction C, we might get result D.\u0026rdquo; This way, the basis of the opinion becomes transparent and traceable.\nMore importantly, this culture encourages treating predictions themselves as hypotheses that need validation. When someone proposes a predictive opinion, the team\u0026rsquo;s natural reaction shouldn\u0026rsquo;t be to directly refute or accept it, but to ask: \u0026ldquo;On what facts and assumptions is this prediction based?\u0026rdquo; and \u0026ldquo;What kind of small experiment can we design to quickly validate this prediction (or its underlying key assumptions)?\u0026rdquo; Thus, predictive discussion is no longer the endpoint, but the starting point for the next round of experiments. It helps us identify the most important uncertainties and explore them at minimal cost, rather than getting bogged down in endless debates about an unverifiable future. This makes opinion discussions also serve the ultimate goal of accumulating facts and reducing uncertainty.\nWhy Is This Important? The shift from \u0026ldquo;I think\u0026rdquo; to \u0026ldquo;I tried\u0026rdquo; brings tangible benefits. The most direct is smarter, faster decisions. When discussions are based on facts rather than eloquence or volume, the time wasted on unproductive arguments is greatly reduced. This is followed by an acceleration of innovation—rapid trial-and-error, rapid learning, rapid iteration, which is exactly the rhythm innovation should have.\nOn a deeper level, consensus built on jointly observed facts is far more stable and meaningful than \u0026ldquo;pseudo-consensus\u0026rdquo; based on compromise or power. This is crucial for improving team collaboration and psychological safety. When discussions revolve around facts, negative emotions and personal attacks arising from conflicting opinions lose their breeding ground. At the same time, because the barrier to \u0026ldquo;trying things out\u0026rdquo; is lowered, members who typically \u0026ldquo;haven\u0026rsquo;t done it\u0026rdquo; can more easily participate, contributing their observations and thoughts. And those who \u0026ldquo;have done the experiment,\u0026rdquo; because the facts are shared, are less likely to develop unnecessary superiority. This naturally fosters a safer, more open environment where different ideas can get a chance for quick validation.\nFurthermore, by conducting experiments firsthand, each member gains direct experience, thereby enhancing the entire team\u0026rsquo;s depth of understanding of the problem domain. This way of working also naturally aligns with the principles of efficient communication—first establish consensus, then focus on resolving differences, making meetings and discussions more productive.\nChallenges Ahead Of course, transformation is not instantaneous. Implementing this culture may encounter some practical challenges. For example, ensuring team members have basic skills in using relevant AI tools (tools and skills) might require some training or guidance. The team also needs to learn how to design meaningful and lightweight experiments (experiment design), avoiding experimentation for experimentation\u0026rsquo;s sake. At the same time, be wary of over-interpreting or misinterpreting experimental data (result interpretation). The biggest challenge might come from cultural inertia; breaking the long-standing habit of \u0026ldquo;meetings are for debating\u0026rdquo; requires time and sustained promotion and demonstration by leaders.\nBut these challenges are not insurmountable; they are more like obstacles to be overcome during the transformation process, rather than unbridgeable gaps.\nConclusion AI is not just a productivity tool; it\u0026rsquo;s more like a catalyst that can reshape our ways of collaboration and team culture. By embracing the rapid experimentation capabilities AI offers, we can liberate our teams from inefficient arguments based on subjective \u0026ldquo;opinions\u0026rdquo; and move towards efficient collaboration based on objective \u0026ldquo;facts.\u0026rdquo;\nFrom \u0026ldquo;I think\u0026rdquo; to \u0026ldquo;I tried\u0026rdquo; is not just a shift in working methods, but an upgrade in mindset. In an era of innovation full of uncertainty, this might be one of the most important changes we can make.\nWhy not start with your next project, your next discussion, and ask yourself and your team: \u0026ldquo;Can we quickly try this with AI?\u0026rdquo;\n","permalink":"https://www.hancezhang.blog/en/posts/experiment-culture/","summary":"\u003cp\u003eWe\u0026rsquo;ve all been in those meetings: discussing a new idea, an innovative project, and then getting bogged down in endless debate. Everyone speaks with conviction, citing classics (or perhaps just an article they saw yesterday), but the discussion seems to go in circles, often ending inconclusively or with the decision made by the loudest voice, the highest-ranking person, or the most stubborn. Why does this happen? Especially in the realm of innovation?\u003c/p\u003e","title":"From 'I Think' to 'I Tried': Building an Experiment-Centric Team Culture with AI"},{"content":"Many of us, especially those who excelled in structured environments like school, carry a particular model of the world into our careers. We tend to believe that advancement, like getting good grades, is the result of a fair, well-calculated, numerical system. Do task A, get 10 points. Do task B, get 20. Rack up enough points, outperform others on the scorecard, and a promotion is the logical outcome. This is the GPA model of career progression.\nBut the reality of the workplace, especially when it comes to decisions like who gets promoted or why a customer buys your product, is often starkly different. It\u0026rsquo;s far less about a transparently calculated score and far more about something much more human, and therefore, much more opaque.\nThe Human Element\nThe first thing to internalize is that decision-makers—your boss, your boss\u0026rsquo;s boss, the investor, the customer—are human. Humans are not consistently rational creatures. If people can be wildly irrational with their own life savings in the stock market, driven by euphoria or panic, how can we expect them to be purely logical, spreadsheet-driven entities when deciding on your career or a purchase?\nThe truth is, many decisions are born from an impression, a feeling. The reasons, the justifications, often come later. They are constructed, sometimes unconsciously, to support a conclusion that was already forming. No one likes to admit they operate on gut feelings, especially in a professional context, so a narrative is woven. But it\u0026rsquo;s often story first, reasons second.\nWhat truly sways these human decision-makers? It\u0026rsquo;s rarely just about the tasks you ticked off. It\u0026rsquo;s about deeper, less quantifiable factors:\nTrust: Does your manager trust you? Not just your competence, but your judgment, your loyalty, your character. Shared Values: Do they see you as \u0026ldquo;one of them\u0026rdquo;? This isn\u0026rsquo;t about blatant cronyism, but a subtle, often subconscious, recognition of shared values, perspectives, or even a sense that you remind them of a younger version of themselves. They\u0026rsquo;re investing in someone they feel they understand and can count on in a less tangible way. Playing the Real Game\nIf the scorecard isn\u0026rsquo;t the whole game, what is? It\u0026rsquo;s about understanding the human landscape you\u0026rsquo;re operating in. The most effective way to get promoted isn\u0026rsquo;t just to be a flawless task-completion machine. It\u0026rsquo;s often to help your manager succeed, to help them get their promotion or achieve their key objectives.\nThis requires you to:\nThink From Their Perspective: What are their pressures? What problems are they trying to solve? What keeps them up at night? Expand Your Scope: Don\u0026rsquo;t just focus on your assigned tasks. See the bigger picture. How does your work contribute to your team\u0026rsquo;s and your manager\u0026rsquo;s goals? Collaborate Proactively: Offer solutions to the problems your manager cares about. If you can make their life easier and help them achieve their aims, you become invaluable in a way that transcends simple task execution. Misconceptions That Hold You Back\nUnderstanding and navigating this human element often bumps up against several widely held, and in my view, damaging, misconceptions.\nMisconception 1: \u0026ldquo;This is just sucking up or playing politics.\u0026rdquo;\nMany, particularly those conditioned by systems that reward individual, measurable achievement (like the exam-based education systems), recoil from this idea. They see it as distasteful, a deviation from a \u0026ldquo;fair\u0026rdquo; world where merit is objectively rewarded. They believe the \u0026ldquo;school system\u0026rdquo; – the world of perfect scores and clear rubrics – is how things should be.\nBut here\u0026rsquo;s the uncomfortable truth: the \u0026ldquo;school system\u0026rdquo; is largely an artificial construct. The world of human interaction, of unspoken cues, of trust built through nuanced relationships – this is the default state of human affairs. It\u0026rsquo;s not an aberration; it\u0026rsquo;s the reality. Learning to navigate it isn\u0026rsquo;t about abandoning principles; it\u0026rsquo;s about understanding the reality. Misconception 2: \u0026ldquo;Maintain strict boundaries; work is just work.\u0026rdquo; The modern emphasis on work-life balance and professional boundaries, while important to prevent burnout and avoid office politics, can sometimes be misused. It can lead to a reductionist, almost mechanical approach to colleagues. \u0026ldquo;They are my upstream; they give me X. I am midstream; I process X and give Y to downstream.\u0026rdquo; While professionalism is key, treating your colleagues – including your boss – as mere cogs in a machine is a mistake. They are people. Perceive their emotions, understand their pressures, listen to their joys and frustrations. You don\u0026rsquo;t need to be best friends, but recognizing their humanity builds the kind of rapport and understanding that oils the wheels of collaboration and trust. Don\u0026rsquo;t \u0026ldquo;gear-ify\u0026rdquo; yourself or others. Misconception 3: \u0026ldquo;I\u0026rsquo;m paid X, so I\u0026rsquo;ll only do X amount of work/thinking.\u0026rdquo;\nMany employees feel that thinking about their boss\u0026rsquo;s problems, or going the extra mile beyond their explicit job description, is uncompensated labor. \u0026ldquo;They don\u0026rsquo;t pay me enough to worry about that.\u0026rdquo;\nThis mindset, while understandable from a purely transactional viewpoint, is incredibly shortsighted. It ignores the power dynamic inherent in most employer-employee relationships. The employer generally holds more bargaining power. If you rigidly stick to \u0026ldquo;I\u0026rsquo;ll only do more if you pay me more first,\u0026rdquo; you\u0026rsquo;re likely to find yourself in a stalemate.\nThe reality is, you often need to be proactive, to demonstrate your value and potential before the greater compensation comes. It\u0026rsquo;s not about being exploited; it\u0026rsquo;s about strategically investing your effort to build the trust and demonstrate the capability that leads to greater opportunities and rewards. Those who only focus on the immediate direct exchange often miss the bigger game. The world of work, like much of life, is governed by these less obvious, more human dynamics. Recognizing this isn\u0026rsquo;t about cynicism; it\u0026rsquo;s about effectiveness. It\u0026rsquo;s about understanding that true advancement often comes not from acing a test, but from building trust, understanding people, and helping them succeed.\n","permalink":"https://www.hancezhang.blog/en/posts/the-scorecard-fallacy/","summary":"Your stellar performance review isn\u0026rsquo;t the key to promotion; the real secret lies in understanding the humans making the decision.","title":"The Scorecard Fallacy: How Promotion Decisions Are Really Made"},{"content":"There\u0026rsquo;s an uncomfortable truth hidden behind the glossy careers pages of big tech companies: most of their hiring isn\u0026rsquo;t driven by genuine necessity, but by abundance.\nCompanies like Google, Meta, or Amazon don\u0026rsquo;t add thousands of new hires every year because each employee is critically essential. They hire simply because they can afford to. Elon Musk illustrated this dramatically at Twitter—laying off 80% of the workforce had surprisingly little impact on the core product. In most tech companies, perhaps only 20% of employees work on truly vital, revenue-driving projects. Google\u0026rsquo;s search and ads make up the lion\u0026rsquo;s share of its revenue, yet only a fraction of its workforce is directly tied to these core areas. Meanwhile, entire teams work on projects that might never ship—projects that are less about necessity and more about optionality.\nWhen companies grow sufficiently rich, hiring stops being about careful selection and becomes something closer to empire-building. It\u0026rsquo;s no longer about who you genuinely need, but rather about who you can afford.\nThink of it like shopping at a supermarket. On a tight budget, you meticulously compare prices, check ingredients, and judge nutritional value. But if you have millions, you won\u0026rsquo;t bother looking carefully. You grab the most expensive items on the shelf, believing price correlates directly with quality—even if it often doesn\u0026rsquo;t. Big companies hire the same way. With abundant resources, they don\u0026rsquo;t thoroughly evaluate the necessity of each new hire. Instead, they hire expensive talent, assuming higher salaries automatically guarantee better results.\nHiring becomes a kind of strategic luxury. Managers don\u0026rsquo;t just expand teams to tackle workloads—they expand to signal their own status and pave the way for promotions. The number of people reporting to a manager usually determines that manager\u0026rsquo;s perceived value and salary within the organization. The head of a 200-person division has more influence, status, and earning potential than someone managing just 20, regardless of how many of those employees genuinely contribute to the company’s core success.\nThere\u0026rsquo;s also optionality at play. Wealthy companies treat hiring as venture capital bets: low-risk investments with potentially huge returns. Many hires are \u0026ldquo;hope it works\u0026rdquo; bets rather than carefully calculated moves. Occasionally, these speculative bets become game-changers—like Google\u0026rsquo;s early investment in AI—but most don\u0026rsquo;t pan out. When a company earns hundreds of billions annually, burning a billion dollars on speculative projects isn\u0026rsquo;t catastrophic—though the same spending would be ruinous for a startup. This mentality often results in highly-qualified people performing mundane tasks: PhDs labeling datasets, master\u0026rsquo;s degree holders managing routine operations—not because these roles demand such expertise, but because optimization for cost-effectiveness isn\u0026rsquo;t necessary.\nWhy should this matter to you? Because it breaks down a dangerous illusion: joining a prestigious tech giant doesn\u0026rsquo;t necessarily mean you\u0026rsquo;re indispensable, valuable, or even secure. History shows, especially vividly around economic downturns (such as the cycle around 2021), that these companies expand and contract largely due to macroeconomic factors like interest rates—not employee performance. When layoffs inevitably occur, the first casualties are often these \u0026ldquo;luxury hires,\u0026rdquo; employees whose roles were never central to the company\u0026rsquo;s essential success.\nIf you\u0026rsquo;re charting your career, particularly early on, understanding this is crucial. Prestige alone can be misleading. Often, the smarter move isn\u0026rsquo;t boarding the largest, most prestigious ship—but one where your work visibly affects the company\u0026rsquo;s trajectory. Seek roles clearly linked to core business outcomes. Find positions where your individual impact is tangible and measurable, not buried beneath layers of internal politics.\n","permalink":"https://www.hancezhang.blog/en/posts/big-tech-hiring/","summary":"Big-tech hiring is driven by excess, not necessity.","title":"Corporates Hire by Abundance, Not by Necessity"},{"content":"People are often amazed by leaders like Steve Jobs and Elon Musk—leaders who seem to bend reality itself to their will. There\u0026rsquo;s even a phrase for it: the Reality Distortion Field (RDF). But what exactly makes this approach so powerful, and why does it seem to work where others fail?\nSteve Jobs was famous for walking into rooms filled with skeptical engineers and walking out leaving a team convinced they could achieve something they\u0026rsquo;d previously considered impossible. Take the early days of the Macintosh. Jobs didn\u0026rsquo;t just demand excellence; he relentlessly questioned assumptions. When engineers argued that the boot-up sequence couldn\u0026rsquo;t possibly be faster, Jobs asked, repeatedly, \u0026ldquo;Why not? What if you had no choice?\u0026rdquo; By removing these implicit constraints, Jobs forced his team to find capabilities within themselves they didn\u0026rsquo;t know existed.\nElon Musk uses a similar strategy at SpaceX and Tesla. An engineer might say rockets can\u0026rsquo;t be reused, or batteries can\u0026rsquo;t be produced cheaply enough for mass-market electric cars. Musk responds: \u0026ldquo;Why not? What\u0026rsquo;s stopping us?\u0026rdquo; Behind these questions is Musk\u0026rsquo;s famous refrain: \u0026ldquo;Physics is the law, everything else is a recommendation.\u0026rdquo; Musk isn\u0026rsquo;t recklessly ignoring reality; he\u0026rsquo;s carefully distinguishing true limitations (physics) from assumptions masquerading as laws.\nBoth Jobs and Musk employ what philosophers call Socratic questioning. Yet people often misunderstand how it works. Merely repeating \u0026ldquo;Why not?\u0026rdquo; isn\u0026rsquo;t enough. Without genuine curiosity and a shared purpose, these questions quickly become annoying or, worse, insulting to the very experts whose cooperation you need. True Socratic questioning isn\u0026rsquo;t about cornering experts or challenging their authority for its own sake. It\u0026rsquo;s about refining knowledge and igniting deeper motivation through collaborative inquiry.\nEffective Socratic questioning involves three critical ingredients:\nFirst, being mission-driven is essential. This isn\u0026rsquo;t just a motivational slogan. A compelling mission provides context and direction, turning seemingly annoying questions into logical, necessary inquiries. Jobs wasn\u0026rsquo;t trying to torment engineers by demanding faster boot times; he was aligning every question with the mission of creating \u0026ldquo;computers for the rest of us.\u0026rdquo; Musk doesn\u0026rsquo;t insist on rocket reusability simply to frustrate his engineers; he does it to enable humanity\u0026rsquo;s future on Mars. The mission clarifies the intent behind the questions, transforming what might seem confrontational into collaborative exploration. When the leader says, \u0026ldquo;I\u0026rsquo;m asking this question to help us achieve our mission,\u0026rdquo; it reframes the dialogue from conflict to shared ambition.\nSecond, you must maintain genuine curiosity—a beginner\u0026rsquo;s mindset. This means asking questions to truly understand, not to prove you\u0026rsquo;re smarter. Jobs often asked questions about technical details because he genuinely wanted to understand them himself. Musk similarly spends significant time diving into the physics and engineering complexities alongside his teams. This genuine curiosity fosters trust and openness, turning skeptical engineers into collaborative partners.\nThird, effective questioning leads the respondent to breakthroughs they feel are their own ideas. Psychologically, people are far more committed to ideas they believe they originated themselves. When a leader guides an expert toward a solution through insightful questioning, the expert feels personal ownership. This dramatically increases motivation and creativity compared to a scenario where solutions are handed down from above.\nOf course, questions alone aren\u0026rsquo;t enough. Jobs didn\u0026rsquo;t just ask questions—he backed them with action, visibly investing resources into prototype development. Musk similarly puts immense personal risk and capital behind his questions. Actions demonstrate commitment far better than words alone, proving to teams that the questions aren\u0026rsquo;t idle or academic.\nWhen used thoughtfully, Socratic questioning doesn\u0026rsquo;t just distort reality—it transforms it. It pushes teams beyond imagined limitations, empowering them to redefine what\u0026rsquo;s possible.\nDistorting reality effectively isn\u0026rsquo;t about denying facts. It\u0026rsquo;s about clarifying them—distinguishing between immutable laws and human-made constraints. Steve Jobs and Elon Musk achieved greatness not by ignoring reality, but by persistently reframing their team\u0026rsquo;s perception of what reality actually allows. By changing the questions their teams asked, they changed the very nature of what their teams believed was achievable.\n","permalink":"https://www.hancezhang.blog/en/posts/rdf/","summary":"Simply doing Socratic questioning can be simply annoying.","title":"Socratic Questioning and the Reality Distortion Field"},{"content":"The best businesses, the ones that really change things, often aren\u0026rsquo;t built for the experts. They\u0026rsquo;re built for everyone else. They take the messy, complicated stuff that only a few truly understand and make it so simple that the other 90% of the world can use it without thinking twice. This isn\u0026rsquo;t about dumbing things down. It\u0026rsquo;s about unlocking potential on a massive scale.\nThe Danger of \u0026ldquo;Technology-First\u0026rdquo; Mindset It\u0026rsquo;s a natural instinct, especially if you\u0026rsquo;re good at something, to want to build for people like you. Engineers want to build for engineers. You get the jargon, the pain points, the subtle details. But here\u0026rsquo;s the catch: building for experts is often a surprisingly under-appreciated task. They\u0026rsquo;re a tough crowd. They know what they\u0026rsquo;re talking about, which means they\u0026rsquo;ll spot every flaw. They can, and will, compare you to every other option out there. And because they could probably build a version of what you\u0026rsquo;re selling themselves, they\u0026rsquo;re not always eager to pay top dollar. It\u0026rsquo;s a world of razor-thin margins and fleeting loyalty.\nYou see this pattern everywhere, not just in software. Think about skincare. Dermatologists will tell you that most of the fancy stuff is unnecessary. A basic routine is often all you need. Yet, the shelves are overflowing with elixirs and multi-step regimens promising miracles. Why? Because for many, it\u0026rsquo;s not just about the science; it\u0026rsquo;s about the ritual, the feeling of control, the story the product tells. Most people aren\u0026rsquo;t biochemists; they\u0026rsquo;re buying hope, or a moment of self-care, packaged in a nice bottle. It\u0026rsquo;s tempting for those who do understand the science to be condescending, to dismiss these consumers as uninformed. But this is a dangerous path, a manifestation of the \u0026ldquo;technology-first\u0026rdquo; mindset. The reality is that the commercial world is driven by user perception and needs, not by an engineer\u0026rsquo;s definition of what users should want or understand. Believing users are simply \u0026ldquo;stupid\u0026rdquo; for not grasping technical nuances is a fast track to building something nobody cares.\nOr consider consumer electronics. We all know that person, the audiophile or the PC builder, who can list a dozen reasons why the popular mainstream product is technically inferior. They\u0026rsquo;ve done the research. They understand the specs. But most people don\u0026rsquo;t buy a speaker because of its frequency response curve. They buy it because it looks good, it\u0026rsquo;s easy to use, and it makes their music sound a bit better. They might not even know exactly what they want, beyond a vague desire for something nice. If you only market to the spec-obsessed, you\u0026rsquo;re talking to a very tiny fraction of the potential audience, also perhaps the most picky ones.\nThe Legend of Apple The early days of Apple illustrate this tension perfectly. Steve Wozniak, an engineering wizard, created Apple I boards that were marvels of ingenuity, elegant in a way only fellow engineers truly appreciated. His designs allowed one to see the logic, trace signals, and understand component interactions. This thrilled the Homebrew Computer Club, tech enthusiasts who loved to tinker, solder, and grasp every circuit. For them, a computer was an open invitation, not a sealed box. They craved modularity: the ability to swap components, experiment with expansion cards, and connect custom peripherals to the system bus. Wozniak\u0026rsquo;s bare-bones designs, with exposed parts, perfectly served this hunger for control, transparency, and endless modification. Users bought the board, sourced their own parts, and the real joy was in building their system.\nJobs saw computers extending beyond the hobbyist niche, accessible even to those unfamiliar with soldering irons or hexadecimal code. To sell the Apple I, he insisted on an assembled motherboard—an idea almost heretical to the Homebrew crowd. He even envisioned a complete, all-in-one machine: take it out of the box, plug it in, and use it. This was a leap. The Homebrew enthusiasts were unimpressed, questioning why they should pay for assembly they could do themselves, preferring open, modifiable systems where they could see the \u0026ldquo;guts.\u0026rdquo; While Wozniak\u0026rsquo;s genius captivated this specific group, Jobs pushed for a product appealing to a much broader audience who didn\u0026rsquo;t know or care what a microprocessor looked like, let alone how to interface with its address lines. Jobs understood that most people didn\u0026rsquo;t want to build computers; they wanted to use them—to write, learn, create. Apple\u0026rsquo;s eventual genius and its path to ubiquity stemmed not just from Woz\u0026rsquo;s technical brilliance, but from Jobs\u0026rsquo; relentless drive to hide that complexity, making the powerful feel effortless for everyone else.\nJony Ive and the Aesthetics of Simplicity This brings us to what simplicity actually means. It\u0026rsquo;s not just about making things look clean. Jony Ive, the former Head of Design at Apple, cautioned that just chasing minimalism can lead to \u0026ldquo;desiccated, soulless\u0026rdquo; products. For Ive, real simplicity had to have utility: \u0026ldquo;If something does not have utility, it\u0026rsquo;s just ugly.\u0026rdquo;\nHe further elaborated on the difficulty of achieving true simplicity. The hard part, Ive said, is first \u0026ldquo;identifying what\u0026rsquo;s truly important.\u0026rdquo; And then, even harder, \u0026ldquo;compressing the complex.\u0026rdquo; It\u0026rsquo;s not about stripping features away randomly. It\u0026rsquo;s about deeply understanding the core purpose of something and then finding the most direct path to its essence.\nIf you\u0026rsquo;re building something, it\u0026rsquo;s tempting to get caught up in the cleverness of your solution, the elegance of your code, the power of your features. We all do it. But the market rarely rewards raw technical prowess alone. It rewards things that solve real problems for real people, easily. If your product requires a manual the size of a phone book, most people will give up. They\u0026rsquo;re not looking for a new intellectual challenge; they\u0026rsquo;re looking for a tool that makes their life a little bit better, right now.\nSo, the next time you see a product that seems \u0026ldquo;too simple\u0026rdquo; or \u0026ldquo;not advanced enough,\u0026rdquo; pause for a moment. It might not be a compromise. It might be a sign of profound insight. It might be that the creators understood something crucial: that the biggest opportunities often lie in taking the power that was once locked away with the experts and giving it to everyone. That\u0026rsquo;s not just good design; it\u0026rsquo;s often great business. The real magic isn\u0026rsquo;t in the complexity you can build, but in the complexity you can hide.\n","permalink":"https://www.hancezhang.blog/en/posts/the-heresy-of-simplicity/","summary":"The best businesses make complexity invisible.","title":"The Heresy of Simplicity"},{"content":"Nassim Taleb says the world is mostly random. Black Swans, pure chance – trying to predict things is a waste of time. Then Peter Thiel, in Zero to One, says great companies are all about careful, deliberate design.\nSo, which is it? If the world\u0026rsquo;s a crapshoot, why bother designing anything?\nWhat \u0026ldquo;Design\u0026rdquo; Really Means\nThe confusion probably starts with what we mean by \u0026ldquo;design.\u0026rdquo; We often think of a perfect blueprint, a detailed plan we follow step-by-step to a known future. If that\u0026rsquo;s design, then yes, in a random world, it\u0026rsquo;s mostly useless.\nBut what if real design isn\u0026rsquo;t about predicting the future? What if it\u0026rsquo;s about building a system that can handle shocks, maybe even get stronger from them? What if it\u0026rsquo;s about what Taleb calls \u0026ldquo;antifragility\u0026rdquo;?\nAntifragile Design: Look at Apple\nSteve Jobs\u0026rsquo; Apple is a good way to see this. It\u0026rsquo;s easy to think Jobs had a crystal ball for tech trends. I doubt it. What Apple got good at was designing a super flexible ecosystem.\nThe App Store is a classic case. Apple didn\u0026rsquo;t know which apps would win. They didn\u0026rsquo;t have to. They just built a platform where thousands of developers could try things out for millions of users. The good stuff rose to the top. So when smartphones became media players, wallets, or AR viewers, Apple didn\u0026rsquo;t need to see it all coming. Their ecosystem was built to let these things happen. Apple wasn\u0026rsquo;t just reacting; they were set up to benefit from whatever came next.\nThat wasn\u0026rsquo;t luck. It was, I bet, a deep grasp of antifragile ideas. Jobs didn\u0026rsquo;t try to nail down one future; he designed for many possibilities by building in options.\nSimplicity is another way to be antifragile. Complex things break easily. More features, more parts, mean more ways for things to go wrong, especially when something unexpected happens. Early smartphones with all their buttons looked clunky fast as new apps appeared. Apple\u0026rsquo;s simple multi-touch screen could handle almost anything. Same with code: tangled code is a disaster when things change; simple, modular code adapts.\nApple often designed by removing stuff. Not just for looks. It was about giving unforeseen problems fewer places to hide. A simpler product is nimbler when the world changes. It\u0026rsquo;s smart defense. It leaves more room for the future, whatever it brings.\nAnd Jobs bet on things that don\u0026rsquo;t change much: people like beauty, ease of use, things that just work. Technology zips along, hard to predict. But what people find elegant? That changes slowly. Betting on those constants is antifragile.\nAntifragility\u0026rsquo;s Two Moves: Building It, Then Riding It\nSo how do these antifragile systems get built? They don\u0026rsquo;t just happen. It takes two kinds of effort, often at different times.\nFirst, there\u0026rsquo;s the sheer force of creation. To build something powerful and antifragile, like Apple\u0026rsquo;s ecosystem or any company from scratch, takes a huge, almost unreasonable push. This is Sam Altman\u0026rsquo;s \u0026ldquo;willfulness.\u0026rdquo; It\u0026rsquo;s the \u0026ldquo;zero to one.\u0026rdquo; You need almost crazy self-belief when everyone else says it won\u0026rsquo;t work. You have to grind, to push through, to make an idea real. Altman notes that the most successful founders often believe in themselves to the point of delusion, think for themselves, take risks, and focus intensely. They know creating something worthwhile often means failing a lot to get one big win. You can\u0026rsquo;t just wait for luck when you\u0026rsquo;re starting with nothing. \u0026ldquo;Design\u0026rdquo; here is messy, iterative, and powered by grit.\nThen, there\u0026rsquo;s strategic patience: riding the wave. Once you\u0026rsquo;ve built your antifragile system, if you get lucky and catch a giant wave – like Apple did with mobile and apps – the smart move might change. This is where \u0026ldquo;Strategic Stillness\u0026rdquo; comes in. Consider Cisco. The founders, Sandy Lerner and Leonard Bosack, did the brutal work of building something new – routers, back when networked computers were just starting. They fought through startup hell, got rejected by VCs endlessly, but finally launched. Then, Cisco went public in 1990. Conflicts with new management arose, and they sold most of their stock for about $170 million. Sounds great, right? But the internet was about to explode, something few could really see in 1990. Cisco\u0026rsquo;s stock shot up nearly a thousand times by 2000. That $170 million could have been tens of billions. They nailed the creation part. But holding on, letting that massive wave of compounding do its thing? That\u0026rsquo;s a different, often harder, game.\nThis \u0026ldquo;strategic stillness\u0026rdquo; isn\u0026rsquo;t about being lazy. It\u0026rsquo;s about seeing that what you\u0026rsquo;ve built, plus the trend it\u0026rsquo;s on, has its own powerful momentum. Too much meddling now can actually hurt. Your initial design did its job; now it\u0026rsquo;s about letting that design and the trend compound.\nFounders or investors who sell out too early from huge successes, like at Cisco, are often masters of that first, willful creation. But they might stumble on strategic patience. Maybe the exhaustion of building, the daily battles, blinds them to the slower, massive opportunity that just needs time. They grab the sure thing now, missing a far bigger, if less certain, payoff later.\nReal Design: For Options and Leverage\nSo, back to the first question: does design matter in a random world? Yes, a lot. But it\u0026rsquo;s not what we usually think.\nIt\u0026rsquo;s not about planning a fixed future. It\u0026rsquo;s about building a flexible setup that keeps benefiting from surprises. This means two things:\nActively Build the Base: Use sheer will to create an antifragile system from nothing. This lays the groundwork. It takes focus, hard work, and fierce belief. Wisely Ride the Current: Once it\u0026rsquo;s working and has momentum, see and use its potential and any big trends. This means strategic patience, letting compounding work. That takes vision, understanding, and the guts to wait. Apple\u0026rsquo;s story has both: Jobs\u0026rsquo;s early, forceful drive, and the later ecosystem that grew by harnessing everyone else\u0026rsquo;s work – a compounding machine.\nDesign Your Approach, Not Destination\nIn a world that keeps surprising you, \u0026ldquo;design\u0026rdquo; becomes less about the specific thing you\u0026rsquo;re making and more about how you make things, how you adapt. You stop trying to fight randomness. You learn to work with it, maybe even use it. You\u0026rsquo;re not drawing a perfect map. You\u0026rsquo;re building a tough, adaptable ship, and learning when to raise the sails and when to drop anchor.\nIn the end, building a startup, investing, or just living your life – the most important design might be how you design your way through uncertainty.\n","permalink":"https://www.hancezhang.blog/en/posts/designing-anti-fragility/","summary":"Great design is not about predicting the future but about crafting the antifragile system","title":"Does Proactive Design still mean anything in the world of randomness?"},{"content":"Brian Chesky, Co-Founder and CEO of Airbnb, has often championed the idea of \u0026ldquo;Founder Mode,\u0026rdquo; a concept popularized by Paul Graham.\nI was immediately drawn to this concept when I first encountered it, but at the time, I interpreted it too narrowly. I thought it simply meant being hands-on rather than hands-off—a shallow view of a profound leadership mindset. This misunderstanding stemmed from Graham\u0026rsquo;s comparison of Founder Mode with \u0026ldquo;Manager Mode,\u0026rdquo; where leaders take a step back, focusing primarily on managing people rather than engaging directly with the work. The hands-on versus hands-off framing felt straightforward, especially since I\u0026rsquo;d seen similar principles in Elon Musk\u0026rsquo;s management philosophy. Musk requires engineering managers to spend at least 20% of their time doing actual engineering. My initial takeaway from this was that leaders need to stay close to the frontlines to understand what\u0026rsquo;s happening and avoid \u0026ldquo;leading without knowing.\u0026rdquo;\nIt wasn\u0026rsquo;t until I encountered leadership challenges in my own work that my understanding of Founder Mode deepened. Around this time, I came across an interview with Brian Chesky that reshaped my thinking. If you manage a team larger than ten people or one with multiple functional units, I highly recommend watching this interview in full—don\u0026rsquo;t double-speed through it.\nBrian distilled Founder Mode into a single sentence: \u0026ldquo;Great leadership is not absence; it\u0026rsquo;s presence.\u0026rdquo; At first, this might sound like the hands-on/hands-off distinction, but Brian\u0026rsquo;s reasoning went deeper than simply understanding the frontlines.\nHe explained this with the analogy of rowing a boat as a team. The goal—rowing forward—sounds simple enough. But in practice, merely stating this goal doesn\u0026rsquo;t suffice. That\u0026rsquo;s why, in rowing, there\u0026rsquo;s often someone at the front of the boat giving real-time guidance. If leaders provide a grand vision and then hand off autonomy to their teams, it can lead to chaos—contrary to what many business schools teach: \u0026ldquo;Hire great people and let them make the decisions.\u0026rdquo; Brian shared that at Airbnb, when different teams worked on the same overarching goal but had too much autonomy, they often ended up with different tech stacks, product designs, and processes that didn\u0026rsquo;t integrate. They were effectively operating as separate organizations. I\u0026rsquo;ve faced this exact issue myself.\nReturning to the rowing analogy, even if everyone is aligned on rowing \u0026ldquo;north,\u0026rdquo; some might row 15% northeast at two strokes per second, while others row 10% northwest at three strokes per second. Everyone is working hard and toward the same goal, but the boat\u0026rsquo;s forward momentum is inefficient. From a physics perspective, the net force driving the boat forward is diluted.\nThis is where Founder Mode becomes critical. Brian pointed to Steve Jobs as a prime example. Jobs didn\u0026rsquo;t simply delegate problems and trust his teams to solve them independently. Instead, he immersed himself in the details of crucial projects—not to micromanage but to collaborate. Leaders in Founder Mode don\u0026rsquo;t act as decision-makers for every issue; they partner with their teams, ensuring alignment with the organization\u0026rsquo;s strategy. This involves providing a clear vision, adding context, and helping to unify efforts across teams. Importantly, Jobs wasn\u0026rsquo;t there to control every decision but to guide and amplify the team\u0026rsquo;s work. This echoes with my previous article Don\u0026rsquo;t Put the Founder on a Pedestal—Or Anyone Else that leaders need to figure out their position and in what way they can best contribute to the team.\nThe secret to avoiding micromanagement lies in how leaders participate. Jobs himself addressed this in an interview when asked if he made all the decisions about product design: \u0026ldquo;I wish I did, but that\u0026rsquo;s what makes Apple the largest startup in the world.\u0026rdquo;\nUltimately, the role of a leader in Founder Mode is to ensure that everyone rows in the same direction with maximum force—not by dictating how they hold the paddle, but by being present, guiding alignment, and keeping the team focused on the larger vision.\n","permalink":"https://www.hancezhang.blog/en/posts/founder-mode/","summary":"Great leadership is not absence; presence","title":"Brian Chesky and Founder Mode"},{"content":"I have a deep respect for the founders at my company; otherwise, I wouldn\u0026rsquo;t still be here. From my perspective, they\u0026rsquo;re all remarkable leaders. But that doesn\u0026rsquo;t contradict the point of this article: idolizing your founder, leader, or anyone else—whether they\u0026rsquo;re Elon Musk, Steve Jobs, or anyone else—is a mistake. The reason is simple: they\u0026rsquo;re not superhuman, no one is.\nOne common misconception is that leaders possess greater technical skill than frontline employees, and people attribute that to their leader\u0026rsquo;s promotion. But leadership is just a different role. It demands a distinct skill set—one that\u0026rsquo;s often rarer and generally more difficult, which tends to earn higher compensation. But that\u0026rsquo;s all there is to it.\nIn an ideal work environment, the leader shouldn\u0026rsquo;t be the one making every decision. If they are, it typically means one of two things:\nThey\u0026rsquo;re micromanaging, or They\u0026rsquo;ve hired people who can\u0026rsquo;t outperform them in specialized areas. Neither scenario is ideal. Instead, a good leader functions as a \u0026ldquo;provider of hidden information\u0026rdquo; and a \u0026ldquo;big-picture decision-maker.\u0026rdquo; Their value lies in vision, strategy, objective-setting, and people skills—not in expertise within every specific domain.\nRecognizing that leaders are simply playing a different role clarifies why idolizing them is risky.\n1. Idolization Leads to Emotional Extremes\nWhen we put leaders on a pedestal, we become prone to emotional extremes. If you believe your leader is right in every decision, eventually reality will show you otherwise. This disillusionment often leads people to the opposite extreme, viewing the leader as entirely flawed. I\u0026rsquo;ve seen this happen repeatedly, and it usually stems from a lack of perspective—a tendency to see leaders as all-knowing, which leaves little room for objective evaluation.\n2. Idolization Can Make You Lose Your Position\nThe best organizations are made up of extraordinary people who excel in their specific areas, and a leader who brings them together and guides the big picture. If you believe your leader is a superhuman, you may start to doubt your own value, perhaps wishing they could be cloned to handle your role, too. But viewing your leader\u0026rsquo;s strengths and weaknesses realistically allows you to better complement their abilities. Great leaders are often self-aware enough to acknowledge their own weaknesses and encourage you to fill in those gaps. But many leaders lack this level of self-awareness, so it\u0026rsquo;s up to you to understand the team\u0026rsquo;s objectives, identify the leader\u0026rsquo;s blind spots, and find your best contribution.\n3. Objectivity Helps You Learn What Leadership Really Involves\nBy dropping the idolization, you can begin to learn what good leadership actually entails. Leaders make big, impactful decisions—and they also make mistakes, often ones that aren\u0026rsquo;t immediately obvious. The only way to understand their decision-making is to examine the trade-offs, anxieties, hesitations, and sometimes even the irrationality behind their choices. Attributing your leader\u0026rsquo;s decision to \u0026ldquo;genius\u0026rdquo; or \u0026ldquo;innate talent\u0026rdquo; won\u0026rsquo;t help you grow. But understanding the practical, often messy reality of leadership just might. Most of the time, you\u0026rsquo;re more like them than you might think.\n","permalink":"https://www.hancezhang.blog/en/posts/no-pedestals/","summary":"Resist the urge to place founders or leaders on pedestals; it hinders growth and critical thinking.","title":"Don't Put the Founder on a Pedestal—Or Anyone Else"},{"content":"How should you manage your time? In one sentence: A leader\u0026rsquo;s job is to ensure the team produces the outcomes that matter most to the company.\nTo break this down, there are four key areas:\nObjective: Identifying what\u0026rsquo;s important and what\u0026rsquo;s not. Strategy: Creating a step-by-step plan to achieve the objective. Executive Management: Ensuring everyone is rowing in the same direction and removing bottlenecks. People Management: Maintaining morale, positioning people for success, and managing hiring and firing. Objective I spend at least 40% of my most productive hours reading, learning, and analyzing the market and technology trends. This is to ensure we have an objective that\u0026rsquo;s both feasible and critical. I can\u0026rsquo;t stress this enough: leaders need to spend more time thinking about what to do than simply doing things. This is particularly important in this era, when things change in a rate which we can\u0026rsquo;t imagine. Keep doing something that\u0026rsquo;s not important has huge opportunity costs.\nStrategy Once you have an objective (or your boss gives you one), strategy becomes essential. Great outcomes rarely happen in one strike. You need a clear step-by-step plan to achieve the goal. Without this, you risk harming your team\u0026rsquo;s performance and morale when early attempts fail. Developing strategy also falls under the 40% of time spent on thinking and planning.\nExecutive Management This is the least glamorous part of leadership—it\u0026rsquo;s repetitive, action-heavy, and often boring. But it compounds over time. You get better at it day by day.\nI spend my \u0026ldquo;not-so-productive\u0026rdquo; hours here: listening to reports, talking to users, speaking with frontline developers, and using the product myself. I minimize indirect reports because they make me lose touch with the ground truth. If a product is underperforming, don\u0026rsquo;t delegate your way out of the problem—use it yourself and talk to users. Lead by example so your team does the same.\nPeople Management People management rarely feels urgent until something goes wrong—like when you need to fire someone or deal with attrition. When it becomes a problem, however, it should be your top priority.\nSam Altman once said the highest ROI for a leader is in hiring. My contrarian view is that I don\u0026rsquo;t trust HR for this task—not just here but in general. Hiring is too important to delegate to someone who has little understanding of your business. The risk is too high.\nUse HR as a tool: let them handle logistics like posting jobs and managing processes. But as a leader, you should proactively seek out great talent yourself. You should know where to find the best people because you are one of them.\nHow should you manage your reports This question depends heavily on your personality and the type of business you\u0026rsquo;re running. For example, my leader doesn\u0026rsquo;t endorse all of my methods—he has his philosophy, and it works for him but not quite for me. My approach is rooted in two principles:\nBeing Detail-Oriented Being Importance-Oriented 1. Being Detail-Oriented Being detail-oriented does not mean micromanaging. For a better understanding, you can refer to my blog on Brian Chesky and Founder Mode .Being detail-oriented means you need to know as much as possible—if not all—about the projects you\u0026rsquo;re overseeing, both technical and non-technical. This is easier than it sounds.\nHowever, you must control the urge to manage every detail directly. If you fail to do this, you\u0026rsquo;ll make life miserable for the people working for you and, worse, erode their initiative—which is critical to building a sustainable organization.\nBeing detail-oriented also requires that you talk directly to the people doing the actual work, not their managers. Bureaucracy thrives when you need to talk to a VP, who then relays the request to a middle manager, who finally asks the people writing the code. This chain is inefficient and prone to information loss.\nSkipping the reporting line is often treated as a taboo in many organizations. But I believe this taboo exists mainly to protect incompetent managers. The people on the front lines are what I call the ground truth of your business. You have no excuse not to access that truth directly.\nOne huge advantage of being detail-oriented is that you can use your unique influence to unblock bottlenecks. Businesses often stall not because the people are incompetent but because they face obstacles they can\u0026rsquo;t resolve on their own. Due to bureaucracy or inertia, they might not ask for help, allowing these bottlenecks to persist. As a leader, being detail-oriented allows you to identify and eliminate these issues effectively.\n2. Being Importance-Oriented Being importance-oriented means ensuring that most of your team\u0026rsquo;s efforts are directed toward solving the most important problem at any given time. A common mistake is when people work hard but on things that don\u0026rsquo;t matter, leading to poor outcomes overall.\nThis is a task only leaders can do because it requires having a broader perspective of the entire business to determine what\u0026rsquo;s important and what\u0026rsquo;s not.\nBeing detail-oriented helps here, too. You can only verify whether your team is working on the most critical problem if you\u0026rsquo;re close to the details. Without this connection, you risk leading the team in the wrong direction.\n","permalink":"https://www.hancezhang.blog/en/posts/self-management-effective-leaders/","summary":"Leadership isn\u0026rsquo;t about innate traits but cultivated skills, especially self-management.","title":"Self Management for Effective Leaders"},{"content":"This is a redacted excerpt from an internal letter I wrote, with all sensitive information removed or masked.\nReaffirming Strategic Principles: Prioritization of Objectives, Trade-Offs on Different Objectives, and Building a Chain of Interconnected Actions\nPrinciple 1: Step by Step The core of a \u0026ldquo;step-by-step\u0026rdquo; approach lies in dynamically shifting perspectives as we make modular progress, ensuring we don\u0026rsquo;t lose the synergy of an integrated business ecosystem. Segmenting different business functions helped avoid internal bottlenecks. Now, in developer product development, \u0026ldquo;step-by-step\u0026rdquo; means avoiding extremes of modularity that isolate teams and instead ensuring that each move integrates tightly with the rest. This step-by-step approach guarantees that our actions form an interconnected chain of progress, rather than haphazard rushes forward.\nEach major product update or expansion initiative should prompt a critical question: Have we connected with all the business lines or resources we have? Are we leveraging the advantages of our integrated ecosystem? Are we laying groundwork for future ecosystem alignment?\nCoordinating closely with other business lines incurs a cost, and we need to acknowledge it. In simple terms, weak performance in one line can pull down others, which means we might not expand modularly as fast as possible. Instead, we must develop the ability to manage increasingly complex loops. By steadfastly building these feedback loops, we enhance the advantages of our integrated ecosystem over the long term, turning them into our core differentiator.\nThe step-by-step principle is also a powerful counter to \u0026ldquo;quick-win\u0026rdquo; expansion strategies. Let\u0026rsquo;s avoid being misled by performance metrics like DAU or MAU, at least for now. Remember: ten users who love you are more valuable than a hundred who only kind of like you. And where does user loyalty come from? From leveraging our ecosystem\u0026rsquo;s strengths.\nLeveraging vertical integration on a smaller scale helps us concentrate our strengths even if, overall, our ecosystem is less mature than competitors\u0026rsquo;. This lets us compete from a stronger position on our chosen ground.\nPrinciple 2: Proximate Goals All leaders have a crucial responsibility: to simplify complex and ambiguous problems and present them in a solvable form for their organization. Many leaders fall short here, often declaring ambitious goals without properly mapping out the obstacles. Taking responsibility doesn\u0026rsquo;t only mean owning up to mistakes but also setting achievable, proximate goals that offer the organization solvable challenges. — Good Strategy, Bad Strategy\nAmbitious goals can drive excitement, but they can also cause confusion and fear. Without achievable, smaller goals, our engineers don\u0026rsquo;t have a clear starting point. We must empower frontline teams with decision-making power, while also reducing the ambiguity they face. Break down goals into tasks whenever possible. Focusing on proximate goals over grand visions keeps the team moving forward.\nProximate goals also provide timely motivation. Building a new business will be a long-term endeavor. We can\u0026rsquo;t expect constant, strong positive feedback from the market, so setting and achieving smaller goals gives our team the positive reinforcement crucial for morale.\nPrinciple 3: Go-To-Market Multiple Times Ninety percent of product ideas are bad—what matters is how quickly you realize they are. — Marc Randolph, Co-founder of Netflix\nConstant market engagement has three main benefits:\nPreventing insularity and creating products people actually need Using new products to probe true market needs (the \u0026ldquo;scouting\u0026rdquo; approach), Testing the reliability of our internal teams. Developing products is like running social experiments. Genius product managers don\u0026rsquo;t create universally-needed products out of thin air; the market is our lab. The faster we obtain real results, the clearer our differentiation from competitors will be. Mark Zuckerberg once said that building products is a turn-based strategy game and the winning secret is to ship it fast to have more turns than others. Accelerate problem exposure, increase visibility of issues, and ensure everyone is accountable for what they build and understands the use cases deeply.\nGetting market feedback is an art. We can\u0026rsquo;t let market requests dictate every move or become tunnel-visioned on internal development goals. The answer is neither, but in accelerating our frequency of market engagement, reducing bias in feedback, and identifying core demands.\nPrinciple 4: Build a User Culture Recognizing that product development will be long-term means understanding that we need an exceptional, durable team. As we noted, we\u0026rsquo;re still in the early stages; the real competition will be even tougher.\nAny member indifferent to user needs or uninterested in the business trajectory could hinder the team down the line. Building a strong team will also be a long-term commitment; rapid turnover of team members would only be another version of the \u0026ldquo;quick-win\u0026rdquo; fallacy. Promoting a strong user culture is a necessity, not an option.\nWhy is this essential?\nIf we\u0026rsquo;re empowering frontline engineers, they must understand user needs deeply; otherwise, they\u0026rsquo;re just following product requirement docs. Eliminate any go-between roles that separate engineers from users; these roles only add noise and delays. Principle three—Go-To-Market Multiple Times—is best served by \u0026ldquo;building in public,\u0026rdquo; where engineers can directly address feedback and bugs. If an engineer can\u0026rsquo;t explain their work clearly, it indicates a need for deeper understanding. This level of clarity is necessary before delegation can be effective. Principle 5: Stay Objective Long-term competition tests our mindset: neither despair nor overconfidence are helpful. To maintain realistic assessments and a steady outlook, we must remind ourselves to stay objective.\nObjectively Assess the Gaps Stay informed of competitor dynamics. Where possible, try competitor products firsthand and monitor market feedback. Avoid being misled by competitors\u0026rsquo; \u0026ldquo;smoke-and-mirrors\u0026rdquo; updates, and keep a realistic view of market prospects and competition intensity.\nRecognize the Twisting Path of Progress Progress is not linear. We\u0026rsquo;re not omniscient and will have to continuously adapt. Don\u0026rsquo;t fall into the trap of assuming \u0026ldquo;A will lead to B.\u0026rdquo; New features won\u0026rsquo;t automatically bring users; multiple factors could be at play. Our aim should be to test widely and cheaply.\nNegative feedback is still feedback. Being criticized by users is better than market silence; it proves that our needs assessment was somewhat accurate.\nPrinciple 6: Stay Attuned to Opportunities Growth over the long term follows a exponential curve, with bursts of short-term volatility. Opportunities are unpredictable, and to grow, we must be prepared to seize them. Our ability to capture these moments must be continually maintained.\n","permalink":"https://www.hancezhang.blog/en/posts/principles-product-development/","summary":"A redacted excerpt from an internal letter on product strategy.","title":"Six Principles to Build a Great Product"},{"content":"One of the most common criticisms of Asian parenting is the lack of unconditional encouragement.\nImagine a Chinese student scoring 90 out of 100 on a final exam—a solid achievement by most standards. Yet, in many cases, this student might face one of two responses. The harsher type of parent might immediately focus on the lost 10 points, saying things like, \u0026ldquo;Why can others score higher than 90, but you can\u0026rsquo;t?\u0026rdquo; or \u0026ldquo;Do you realize how many people will outscore you in the Gaokao (the Chinese College Entrance Exam) if you keep losing points like this?\u0026rdquo; The more considerate type of parent might start with a brief compliment, \u0026ldquo;You did a good job,\u0026rdquo; but then quickly pivot to a debriefing session: \u0026ldquo;Now, let\u0026rsquo;s analyze why you missed those 10 points. Can you be less careless next time?\u0026rdquo;\nBoth types of parents believe they\u0026rsquo;re acting out of love and doing what\u0026rsquo;s best for their child. In Chinese culture, pride is often seen as a slippery slope to complacency, and complacency is viewed as one of the most dangerous mindsets. So, these parents feel an almost moral obligation to nip any signs of pride in the bud. They fear that if they don\u0026rsquo;t, they\u0026rsquo;ll be failing to prepare their child for the future.\nBut let\u0026rsquo;s be honest—what are the odds that the child will actually take this advice to heart and become less careless in the future? The chances are slim to none. If the child is proud of their achievement, they\u0026rsquo;re likely in a celebratory mood, eager to share their success with their parents out of love and a desire for validation. If your child no longer shares their successes with you, that\u0026rsquo;s a clear sign of a deeper issue in your relationship—don\u0026rsquo;t doubt that.\nAs a parent, the best course of action in this moment is simple: celebrate with your child. Why? Because your \u0026ldquo;constructive feedback\u0026rdquo; won\u0026rsquo;t be valued or even heard. The child will either ignore or resent the advice, resent you for pouring cold water on their happiness, or even start to dislike the project itself because it brought them no sense of achievement.\nIf you want someone to improve at anything, you must first build a positive reinforcement loop. This includes offering genuine, unconditional praise when they succeed. If you truly want your child to get better, save the constructive feedback for a setting where they themselves acknowledge that their performance was below expectations. It\u0026rsquo;s even better if your child comes to you seeking advice after things go wrong—but that level of trust requires a solid foundation.\nWhat I\u0026rsquo;ve said here doesn\u0026rsquo;t just apply to parenting—it applies to the workplace and all human interactions. Providing advice is an art that requires careful consideration of how, when, and where you do it. Dumping advice without regard for the situation might make you feel like you\u0026rsquo;re being honest, objective, and promoting a growth mindset. But in reality, you\u0026rsquo;re just satisfying a didactic craving and reflecting a sense of arrogance. Most of the time, people aren\u0026rsquo;t in the right frame of mind to receive feedback, and your untimely advice will only backfire.\n","permalink":"https://www.hancezhang.blog/en/posts/constructive-feedback/","summary":"Protect the positive reinforcement loop if you really wish others to grow","title":"How to Provide Advice in a Helpful Way"},{"content":"I\u0026rsquo;ve been delving into the phenomenon known as Steve Jobs\u0026rsquo; reality distortion field, trying to grasp how he pulled it off. This led me to an intriguing insight, partly inspired by a famous TED Talk by Simon Sinek.\nMediocre salespeople sell products—they make you buy a thing. Good salespeople sell a lifestyle—they make you buy into an idea. But the truly extraordinary, those who often become charismatic leaders, they sell visions—they sell the \u0026ldquo;why.\u0026rdquo;\nI find it astonishing that most people don\u0026rsquo;t proactively think of the \u0026ldquo;why\u0026rdquo; in their own work. They complain about being treated like tools in a corporate machine, yet they willingly instrumentalize themselves. They\u0026rsquo;ve programmed their minds to function like a tool: receive input, produce the desired output, repeat. They don\u0026rsquo;t question why the work is being done, in what context it adds value, or whether there might be a better way. They clock in, complete the tasks assigned, submit their work, and do it all over again the next day. How can anyone be surprised when the corporate machine treats them like a tool if that\u0026rsquo;s the life they\u0026rsquo;ve chosen?\nIn our workplace, there\u0026rsquo;s a principle we call the 7/2/1 rule. It means that in an ideal business unit, 70% of the people are focused on the tasks handed to them—the what. Their role is to take the inputs and deliver quality outputs. 20% are tasked with figuring out the best way to accomplish those tasks—the how. And the remaining 10% engage in the strategic discussions, deciding what to do and why to do it—the why. In real-world practice, I find it\u0026rsquo;s more like a 85/10/5 division.\nThe brutal reality is that many people struggle to find a \u0026ldquo;why\u0026rdquo; in their work or life. This sense of meaninglessness is, in part, a byproduct of capitalism\u0026rsquo;s rise and the decline of religion. Yet, people need a \u0026ldquo;why.\u0026rdquo; And if you can be the person who identifies a compelling \u0026ldquo;why\u0026rdquo; and sells it to others, they\u0026rsquo;ll work tirelessly for it—and it won\u0026rsquo;t even be about the money.\nThis is where strong, influential leadership comes into play. It\u0026rsquo;s exactly what Jobs did when he convinced John Sculley to leave Pepsi for Apple: \u0026ldquo;Do you want to spend the rest of your life selling sugared water, or do you want a chance to change the world?\u0026rdquo; Apple\u0026rsquo;s vision—affordable, delicatedly designed personal computers—was a much stronger \u0026ldquo;why\u0026rdquo; than selling soda.\nThe world isn\u0026rsquo;t short of hardworking, intelligent, and well-trained people. But only a few possess the agility to adapt to the market change, the strategic vision to see ahead, and the charisma to sell those \u0026ldquo;whys\u0026rdquo; to both employees and customers.\n","permalink":"https://www.hancezhang.blog/en/posts/selling-whys/","summary":"Find a compelling why and sell it.","title":"Selling Whys"},{"content":"A truly natural impulse I quickly discovered my passion for writing, which I enjoy even more than reading. My father, a former writer turned entrepreneur, likely influenced me. I started writing at a young age in elementary school, with poetry as my first love.\nWriting feels more like a natural impulse than a duty. If I don\u0026rsquo;t write, I feel discomfort. With countless thoughts circling in my mind, writing provides a release, almost like a cure.\nI recognize the benefits of writing: it helps in reorganizing thoughts, formulating structured ideas, and consolidating understanding, as Feynman emphasized in his learning method. However, these benefits don\u0026rsquo;t push me to write. I write because I feel uneasy if I don\u0026rsquo;t. I truly believe that\u0026rsquo;s how humanity works for most people: a habit is sustainable only if it feels like a constant, urgent demand from within. Merely stating \u0026ldquo;it\u0026rsquo;s a good habit to have\u0026rdquo; rarely motivates people to adopt it.\nI used to organize my thoughts using the iPhone\u0026rsquo;s native memo app. But as I graduated from college, my thoughts became more complex and systematic, beyond what a simple memo could handle. So, I decided to start blogging.\nA window for people to know me, aka personal branding Whenever I meet a new interesting person, or catching up with some old friends, I really do have a lot to share, and those sharing are generally less about news but more about learnings. As I met more interesting people daily (a good sign!), I felt the repetition of introducing my learnings has been annoying enough that I wanted some form of automation, and blogging seems to be a great way to do it.\nBlogging also helps me build a personal brand. I believe personal branding is an underestimated asset in its impact and overestimated in its cost. Like any other asset, personal branding yields compound interest. Starting early on the path of exponential growth can lead to significant rewards in the end.\nI\u0026rsquo;m lazy, uninterested, and incompetent in other form of medias (music, art, video, and others), which makes blogging a no-brainer.\nPractice writing Even though I often claim I\u0026rsquo;m bilingual in both Chinese and English, I must confess I\u0026rsquo;m terrible at both in writing very concise, elegant articles (I admire George Orwell for that). Often times my English writing sounds Chinese-translated, and vice versa. In reality, my natural writing style is a blend of both languages.\nGiven that the potential audience of this blog primarily uses Chinese and English, I\u0026rsquo;ve decided to make the blog bilingual. This will also help me practice and improve my writing skills in both languages.\nOn originality I won\u0026rsquo;t claim much originality in my writing. Most of my content is a personal reinterpretation of ideas from great minds I admire. I draw inspiration mainly from the works of Elon Musk, Paul Graham, Sam Altman, Brain Chesky, Steve Jobs and Naval Ravikant, among others.(keep adding on this list..)\n","permalink":"https://www.hancezhang.blog/en/posts/why-i-write-blogs/","summary":"Exploring the motivations behind blogging, from clarifying thoughts to sharing knowledge.","title":"Why I Write Blogs?"}]